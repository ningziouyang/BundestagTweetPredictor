{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c52efb2a",
   "metadata": {},
   "source": [
    "# **1. Daten einlesen**\n",
    "In diesem Schritt lesen wir alle `.jl`-Dateien aus dem Verzeichnis `../twitter-bundestag-2022/data/` ein, extrahieren die Tweet-Texte und die zugeh√∂rige Partei, und speichern die Daten als CSV-Datei f√ºr die weitere Verarbeitung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebd7a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# List to collect all tweets\n",
    "all_data = []\n",
    "\n",
    "# Iterate through all .jl files in the data folder\n",
    "for filepath in glob.glob(\"../twitter-bundestag-2022/data/*.jl\"):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        partei = None\n",
    "\n",
    "        for line in file:\n",
    "            entry = json.loads(line)\n",
    "\n",
    "            # Extract party from account_data, usually in the first line\n",
    "            if not partei and \"account_data\" in entry:\n",
    "                partei = entry[\"account_data\"].get(\"Partei\", \"Unbekannt\")\n",
    "\n",
    "            # Extract tweets from lines with \"response\"\n",
    "            if \"response\" in entry:\n",
    "                tweets = entry[\"response\"].get(\"data\", [])\n",
    "                for tweet in tweets:\n",
    "                    text = tweet.get(\"text\", \"\")\n",
    "                    if text:\n",
    "                        all_data.append({\n",
    "                            \"text\": text,\n",
    "                            \"partei\": partei\n",
    "                        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c86dc44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets insgesamt: 3801087\n",
      "Spalten: ['text', 'partei']\n",
      "                                                      text  \\\n",
      "1856936  RT @SenWiEnBe: Auch die neuen Zahlen belegen: ...   \n",
      "814722   @handelsblatt Wenn dem #Bundeskanzler ‚Äûbesonde...   \n",
      "3239937     Mein Weg zur Arbeit ... http://t.co/C2sgbwBOtX   \n",
      "2352165  Falsche Behauptungen √ºber Personen sind heute ...   \n",
      "3502626  B√ºhne frei f√ºr allerleiüò≤, auch in Orientalen.....   \n",
      "\n",
      "                        partei  \n",
      "1856936  B√ºndnis 90/Die Gr√ºnen  \n",
      "814722                     CDU  \n",
      "3239937                    SPD  \n",
      "2352165              Die Linke  \n",
      "3502626                    AfD  \n",
      "\n",
      "Tweets pro Partei:\n",
      "partei\n",
      "B√ºndnis 90/Die Gr√ºnen    922789\n",
      "SPD                      794275\n",
      "CDU                      623217\n",
      "Die Linke                540002\n",
      "FDP                      383721\n",
      "AfD                      281167\n",
      "CSU                      168803\n",
      "Fraktionslos              87113\n",
      "Name: count, dtype: int64\n",
      "CSV gespeichert unter: tweets_bundestag.csv\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Show basic info\n",
    "print(f\"Tweets insgesamt: {len(df)}\")\n",
    "print(\"Spalten:\", df.columns.tolist())\n",
    "if not df.empty:\n",
    "    print(df.sample(5, random_state=1))\n",
    "\n",
    "# Show party distribution\n",
    "print(\"\\nTweets pro Partei:\")\n",
    "print(df[\"partei\"].value_counts())\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"tweets_bundestag.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"CSV gespeichert unter: tweets_bundestag.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a98c5",
   "metadata": {},
   "source": [
    "## **2. Baseline-Modell**\n",
    "Wir erstellen ein erstes Modell nur auf Basis des unbearbeiteten Tweet-Textes.  \n",
    "Ziel ist es, eine einfache Vergleichsbasis zu schaffen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06c5d57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbleibende Parteien: ['CDU' 'Die Linke' 'SPD' 'B√ºndnis 90/Die Gr√ºnen' 'FDP' 'CSU' 'AfD'\n",
      " 'Fraktionslos']\n",
      "Tweets pro Partei im Sample:\n",
      " partei\n",
      "B√ºndnis 90/Die Gr√ºnen    12205\n",
      "SPD                      10496\n",
      "CDU                       8206\n",
      "Die Linke                 7117\n",
      "FDP                       5030\n",
      "AfD                       3637\n",
      "CSU                       2195\n",
      "Fraktionslos              1114\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Filter out unknown or too-small parties\n",
    "min_tweet_count = 1000\n",
    "valid_parties = df[\"partei\"].value_counts()[df[\"partei\"].value_counts() >= min_tweet_count].index\n",
    "df = df[df[\"partei\"].isin(valid_parties) & (df[\"partei\"] != \"Unbekannt\")]\n",
    "\n",
    "# Optional: Downsample if dataset is huge\n",
    "max_samples = 50000\n",
    "if len(df) > max_samples:\n",
    "    df = df.sample(n=max_samples, random_state=42)\n",
    "\n",
    "print(f\"Verbleibende Parteien: {df['partei'].unique()}\")\n",
    "print(\"Tweets pro Partei im Sample:\\n\", df[\"partei\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b19ef3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stratified train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], df[\"partei\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"partei\"]\n",
    ")\n",
    "\n",
    "# TF-IDF vectorization (keep hashtags, mentions, emojis, URLs for now)\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Logistic Regression baseline\n",
    "clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42)\n",
    "clf.fit(X_train_vec, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2601b5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                  AfD      0.489     0.579     0.530       727\n",
      "B√ºndnis 90/Die Gr√ºnen      0.568     0.401     0.470      2441\n",
      "                  CDU      0.465     0.395     0.427      1641\n",
      "                  CSU      0.212     0.453     0.289       439\n",
      "            Die Linke      0.421     0.452     0.436      1424\n",
      "                  FDP      0.404     0.406     0.405      1006\n",
      "         Fraktionslos      0.070     0.283     0.113       223\n",
      "                  SPD      0.497     0.390     0.437      2099\n",
      "\n",
      "             accuracy                          0.418     10000\n",
      "            macro avg      0.391     0.420     0.388     10000\n",
      "         weighted avg      0.466     0.418     0.433     10000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[421  32  36  45  48  39  67  39]\n",
      " [114 980 215 170 330 176 188 268]\n",
      " [ 72 157 648 157 132 121 148 206]\n",
      " [ 15  41  69 199  30  14  29  42]\n",
      " [ 56 184  92 103 643  77 125 144]\n",
      " [ 56  96  84  65  97 408  99 101]\n",
      " [ 33  30  18  10  20  20  63  29]\n",
      " [ 94 206 233 189 227 156 175 819]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=3))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563421d5",
   "metadata": {},
   "source": [
    "## **3. Explorative Datenanalyse**\n",
    "Wir untersuchen grundlegende Eigenschaften des Datensatzes. Die Einblicke helfen uns sp√§ter bei Entscheidungen f√ºr das Preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "54f03dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Filter out small/unknown parties for clearer analysis\n",
    "min_tweet_count = 1000\n",
    "df = df[df[\"partei\"].map(df[\"partei\"].value_counts()) >= min_tweet_count]\n",
    "df = df[df[\"partei\"] != \"Unbekannt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2151999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction functions\n",
    "def count_emojis(text):\n",
    "    return sum(char in emoji.EMOJI_DATA for char in str(text))\n",
    "\n",
    "def count_hashtags(text):\n",
    "    return len(re.findall(r\"#\\w+\", str(text)))\n",
    "\n",
    "def count_mentions(text):\n",
    "    return len(re.findall(r\"@\\w+\", str(text)))\n",
    "\n",
    "def count_urls(text):\n",
    "    return len(re.findall(r\"http\\S+|www\\S+|https\\S+\", str(text)))\n",
    "\n",
    "# Apply features\n",
    "df[\"num_emojis\"] = df[\"text\"].apply(count_emojis)\n",
    "df[\"num_hashtags\"] = df[\"text\"].apply(count_hashtags)\n",
    "df[\"num_mentions\"] = df[\"text\"].apply(count_mentions)\n",
    "df[\"num_urls\"] = df[\"text\"].apply(count_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59a397be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Durchschnittliche Feature-Anzahl pro Partei:\n",
      "                        num_emojis  num_hashtags  num_mentions  num_urls\n",
      "partei                                                                 \n",
      "FDP                      0.255666      0.862425      1.245726  0.423459\n",
      "AfD                      0.249656      1.384383      1.025296  0.553478\n",
      "CSU                      0.164920      0.608656      1.146241  0.384055\n",
      "Fraktionslos             0.154399      0.416517      1.050269  0.433573\n",
      "SPD                      0.138529      0.684165      1.163396  0.418540\n",
      "B√ºndnis 90/Die Gr√ºnen    0.138058      0.897173      1.254076  0.430807\n",
      "CDU                      0.123203      0.808555      1.180600  0.441506\n",
      "Die Linke                0.100745      1.010960      1.015175  0.498806\n"
     ]
    }
   ],
   "source": [
    "# Show descriptive statistics\n",
    "summary = df.groupby(\"partei\")[[\"num_emojis\", \"num_hashtags\", \"num_mentions\", \"num_urls\"]].mean().sort_values(by=\"num_emojis\", ascending=False)\n",
    "print(\"\\nDurchschnittliche Feature-Anzahl pro Partei:\\n\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "afd0406c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(summary, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
    "plt.title(\"Durchschnittliche Anzahl von Emojis, Hashtags, Mentions und URLs pro Tweet (nach Partei)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aff7e3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Hashtags insgesamt:\n",
      " text\n",
      "#AfD          921\n",
      "#Bundestag    578\n",
      "#SPD          494\n",
      "#CDU          382\n",
      "#Berlin       324\n",
      "#Corona       320\n",
      "#Merkel       304\n",
      "#FDP          272\n",
      "#EU           209\n",
      "#CSU          201\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 10 Mentions insgesamt:\n",
      " text\n",
      "@cducsubt           543\n",
      "@spdde              498\n",
      "@spdbt              452\n",
      "@GrueneBundestag    447\n",
      "@CDU                402\n",
      "@Die_Gruenen        371\n",
      "@fdpbt              334\n",
      "@fdp                318\n",
      "@c_lindner          306\n",
      "@Linksfraktion      294\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Example for hashtags:\n",
    "def get_top_n(pattern, n=10):\n",
    "    all_matches = df[\"text\"].str.findall(pattern).explode()\n",
    "    return all_matches.value_counts().head(n)\n",
    "\n",
    "print(\"\\nTop 10 Hashtags insgesamt:\\n\", get_top_n(r\"#\\w+\"))\n",
    "print(\"\\nTop 10 Mentions insgesamt:\\n\", get_top_n(r\"@\\w+\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3623b573",
   "metadata": {},
   "source": [
    "## **4. Preprocessing (mit Varianten)**\n",
    "Wir untersuchen verschiedene Preprocessing-Strategien. Ziel: Verschiedene Varianten vorbereiten, die wir anschlie√üend in der Modellierung vergleichen k√∂nnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25808f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "# Variant 1 functions\n",
    "def remove_urls(text):\n",
    "    return re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", str(text))\n",
    "\n",
    "def remove_mentions(text):\n",
    "    return re.sub(r\"@\\w+\", \"\", str(text))\n",
    "\n",
    "def clean_hashtags(text, keep_hash=True):\n",
    "    if keep_hash:\n",
    "        return str(text)\n",
    "    return re.sub(r\"#(\\w+)\", r\"\\1\", str(text))\n",
    "\n",
    "def emoji_to_text(text, demojize=True):\n",
    "    if demojize:\n",
    "        return emoji.demojize(str(text), delimiters=(\" \", \" \"))\n",
    "    return str(text)\n",
    "\n",
    "def preprocess_variant(\n",
    "    text,\n",
    "    lower=True,\n",
    "    remove_url=False,\n",
    "    remove_mention=False,\n",
    "    remove_hash_symbol=False,\n",
    "    demojize=False\n",
    "):\n",
    "    t = str(text)\n",
    "    if lower:\n",
    "        t = t.lower()\n",
    "    if remove_url:\n",
    "        t = remove_urls(t)\n",
    "    if remove_mention:\n",
    "        t = remove_mentions(t)\n",
    "    t = clean_hashtags(t, keep_hash=not remove_hash_symbol)\n",
    "    t = emoji_to_text(t, demojize=demojize)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44ae4f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variant 2 (special token) functions\n",
    "def replace_urls(text):\n",
    "    return re.sub(r\"http\\S+|www\\S+|https\\S+\", \" URL \", str(text))\n",
    "\n",
    "def replace_mentions(text):\n",
    "    return re.sub(r\"@\\w+\", \" USER \", str(text))\n",
    "\n",
    "def special_hashtags(text):\n",
    "    # Replace #hashtag with HASHTAG_hashtag\n",
    "    return re.sub(r\"#(\\w+)\", r\"HASHTAG_\\1\", str(text))\n",
    "\n",
    "def preprocess_specialtok(text):\n",
    "    t = str(text).lower()\n",
    "    t = replace_urls(t)\n",
    "    t = replace_mentions(t)\n",
    "    t = special_hashtags(t)\n",
    "    t = emoji_to_text(t, demojize=True)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ced775a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved variant: raw to tweets_bundestag_raw.csv\n",
      "Saved variant: lowercase to tweets_bundestag_lowercase.csv\n",
      "Saved variant: no_urls to tweets_bundestag_no_urls.csv\n",
      "Saved variant: no_mentions to tweets_bundestag_no_mentions.csv\n",
      "Saved variant: no_urls_mentions to tweets_bundestag_no_urls_mentions.csv\n",
      "Saved variant: demojize to tweets_bundestag_demojize.csv\n",
      "Saved variant: no_hashsymbol to tweets_bundestag_no_hashsymbol.csv\n",
      "Saved variant: no_urls_mentions_demojize to tweets_bundestag_no_urls_mentions_demojize.csv\n",
      "Example cleaned texts (Variant 1):\n",
      "                                                text\n",
      "0  RT @OleKreins: Aber bitte nicht das Tempelhofe...\n",
      "1  @tirsales Leider wird oft vergessen, dass Face...\n",
      "2  RT @SenIAS_Berlin: Arabisch, Farsi, Kurdisch, ...\n",
      "3  RT @DanielGollasch: Wann wird denn der Hashtag...\n",
      "4  RT @Dirk_Behrendt: Heute gedachten wir am @t4e...\n",
      "5  RT @berlinliebich: Wenn doch SPD und Gr√ºne nur...\n",
      "6  RT @AndrejHunko: Drohnenangriffe: Regierung wi...\n",
      "7  RT @juhessen: Heute Abend k√§mpft Jennifer Brau...\n",
      "8  RT @JuliaKloeckner: Peinlich, MP traut sich ni...\n",
      "9  @DerWesten Hinzuweisen ist auch auf die ausufe...\n",
      "Example special token cleaned texts:\n",
      "0    rt USER : aber bitte nicht das tempelhofer fel...\n",
      "1    USER leider wird oft vergessen, dass facebook ...\n",
      "2    rt USER : arabisch, farsi, kurdisch, franz√∂sis...\n",
      "3    rt USER : wann wird denn der hashtag HASHTAG_1...\n",
      "4    rt USER : heute gedachten wir am USER der opfe...\n",
      "5    rt USER : wenn doch spd und gr√ºne nur nicht so...\n",
      "6    rt USER : drohnenangriffe: regierung will weit...\n",
      "7    rt USER : heute abend k√§mpft jennifer braun au...\n",
      "8    rt USER : peinlich, mp traut sich nicht, i der...\n",
      "9    USER hinzuweisen ist auch auf die ausufernde b...\n",
      "Name: specialtok_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"../tweets_bundestag.csv\", encoding=\"utf-8-sig\")\n",
    "    min_tweet_count = 1000\n",
    "    df = df[df[\"partei\"].map(df[\"partei\"].value_counts()) >= min_tweet_count]\n",
    "    df = df[df[\"partei\"] != \"Unbekannt\"]\n",
    "    df = df.sample(n=50000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Save different preprocessing variants for ablation studies (Variant 1)\n",
    "    variants = {\n",
    "        \"raw\": df[\"text\"],\n",
    "        \"lowercase\": df[\"text\"].apply(lambda x: preprocess_variant(x, lower=True, remove_url=False, remove_mention=False, demojize=False, remove_hash_symbol=False)),\n",
    "        \"no_urls\": df[\"text\"].apply(lambda x: preprocess_variant(x, lower=True, remove_url=True, remove_mention=False, demojize=False, remove_hash_symbol=False)),\n",
    "        \"no_mentions\": df[\"text\"].apply(lambda x: preprocess_variant(x, lower=True, remove_url=False, remove_mention=True, demojize=False, remove_hash_symbol=False)),\n",
    "        \"no_urls_mentions\": df[\"text\"].apply(lambda x: preprocess_variant(x, lower=True, remove_url=True, remove_mention=True, demojize=False, remove_hash_symbol=False)),\n",
    "        \"demojize\": df[\"text\"].apply(lambda x: preprocess_variant(x, lower=True, remove_url=False, remove_mention=False, demojize=True, remove_hash_symbol=False)),\n",
    "        \"no_hashsymbol\": df[\"text\"].apply(lambda x: preprocess_variant(x, lower=True, remove_url=False, remove_mention=False, demojize=False, remove_hash_symbol=True)),\n",
    "        \"no_urls_mentions_demojize\": df[\"text\"].apply(lambda x: preprocess_variant(x, lower=True, remove_url=True, remove_mention=True, demojize=True, remove_hash_symbol=False)),\n",
    "    }\n",
    "\n",
    "    for variant, series in variants.items():\n",
    "        out = df[[\"partei\"]].copy()\n",
    "        out[\"text\"] = series\n",
    "        out.to_csv(f\"tweets_bundestag_{variant}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"Saved variant: {variant} to tweets_bundestag_{variant}.csv\")\n",
    "\n",
    "    print(\"Example cleaned texts (Variant 1):\")\n",
    "    print(df.head(10)[[\"text\"]])\n",
    "\n",
    "    # Special token variant (Variant 2)\n",
    "    df[\"specialtok_text\"] = df[\"text\"].apply(preprocess_specialtok)\n",
    "    df[[\"specialtok_text\", \"partei\"]].to_csv(\"tweets_bundestag_specialtok.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"Example special token cleaned texts:\")\n",
    "    print(df[\"specialtok_text\"].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77897807",
   "metadata": {},
   "source": [
    "## **5. Modellvergleich: Verschiedene Preprocessing-Varianten**\n",
    "\n",
    "In diesem Schritt evaluieren wir, wie sich verschiedene Text-Bereinigungsvarianten auf die Modellleistung auswirken.  \n",
    "Wir verwenden als Modell:\n",
    "- TF-IDF-Vektorisierung\n",
    "- Logistische Regression\n",
    "\n",
    "Kennzahlen:\n",
    "- Accuracy\n",
    "- F1-Score (macro & weighted)\n",
    "\n",
    "Verglichen werden u.‚ÄØa.:\n",
    "- Raw Text\n",
    "- Ohne URLs\n",
    "- Ohne Mentions\n",
    "- Emojis als Text\n",
    "- Spezielle Tokens wie USER / URL etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d1376e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing variant: raw ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.415, Macro F1: 0.387, Weighted F1: 0.431\n",
      "\n",
      "=== Testing variant: lowercase ===\n",
      "Accuracy: 0.415, Macro F1: 0.387, Weighted F1: 0.431\n",
      "\n",
      "=== Testing variant: no_urls ===\n",
      "Accuracy: 0.423, Macro F1: 0.389, Weighted F1: 0.437\n",
      "\n",
      "=== Testing variant: no_mentions ===\n",
      "Accuracy: 0.295, Macro F1: 0.276, Weighted F1: 0.305\n",
      "\n",
      "=== Testing variant: no_urls_mentions ===\n",
      "Accuracy: 0.299, Macro F1: 0.279, Weighted F1: 0.309\n",
      "\n",
      "=== Testing variant: demojize ===\n",
      "Accuracy: 0.416, Macro F1: 0.388, Weighted F1: 0.431\n",
      "\n",
      "=== Testing variant: no_hashsymbol ===\n",
      "Accuracy: 0.414, Macro F1: 0.386, Weighted F1: 0.430\n",
      "\n",
      "=== Testing variant: no_urls_mentions_demojize ===\n",
      "Accuracy: 0.307, Macro F1: 0.286, Weighted F1: 0.317\n",
      "\n",
      "=== Testing variant: specialtok ===\n",
      "Accuracy: 0.290, Macro F1: 0.274, Weighted F1: 0.300\n",
      "\n",
      "=== Summary Table ===\n",
      "                     variant  accuracy  macro_f1  weighted_f1\n",
      "0                        raw  0.415500  0.387152     0.430914\n",
      "1                  lowercase  0.415500  0.387152     0.430914\n",
      "2                    no_urls  0.423174  0.389051     0.437171\n",
      "3                no_mentions  0.295389  0.276226     0.305492\n",
      "4           no_urls_mentions  0.298881  0.278595     0.308512\n",
      "5                   demojize  0.416300  0.388493     0.430825\n",
      "6              no_hashsymbol  0.414300  0.386097     0.429702\n",
      "7  no_urls_mentions_demojize  0.306847  0.286434     0.316600\n",
      "8                 specialtok  0.290000  0.273709     0.300219\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "variants = [\n",
    "    \"raw\",\n",
    "    \"lowercase\",\n",
    "    \"no_urls\",\n",
    "    \"no_mentions\",\n",
    "    \"no_urls_mentions\",\n",
    "    \"demojize\",\n",
    "    \"no_hashsymbol\",\n",
    "    \"no_urls_mentions_demojize\",\n",
    "    \"specialtok\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for variant in variants:\n",
    "    print(f\"\\n=== Testing variant: {variant} ===\")\n",
    "    df = pd.read_csv(f\"tweets_bundestag_{variant}.csv\", encoding=\"utf-8-sig\")\n",
    "    df = df.dropna(subset=[\"text\" if variant != \"specialtok\" else \"specialtok_text\"])\n",
    "    text_col = \"text\" if variant != \"specialtok\" else \"specialtok_text\"\n",
    "    min_tweet_count = 1000\n",
    "    df = df[df[\"partei\"].map(df[\"partei\"].value_counts()) >= min_tweet_count]\n",
    "    sample_size = min(50000, len(df))\n",
    "    df = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[text_col], df[\"partei\"],\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=df[\"partei\"]\n",
    "    )\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42)\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    weighted_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"Accuracy: {acc:.3f}, Macro F1: {macro_f1:.3f}, Weighted F1: {weighted_f1:.3f}\")\n",
    "    results.append({\n",
    "        \"variant\": variant,\n",
    "        \"accuracy\": acc,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"weighted_f1\": weighted_f1\n",
    "    })\n",
    "\n",
    "print(\"\\n=== Summary Table ===\")\n",
    "print(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe68e33c",
   "metadata": {},
   "source": [
    "## **6. TF-IDF Baseline**\n",
    "\n",
    "In diesem Abschnitt trainieren wir den Baseline Modell und speichern das Modell sowie den TF-IDF-Vektorisierer mit `joblib` f√ºr sp√§tere Nutzung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44ef1aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in data:\n",
      " partei\n",
      "B√ºndnis 90/Die Gr√ºnen    12185\n",
      "SPD                      10424\n",
      "CDU                       8172\n",
      "Die Linke                 7071\n",
      "FDP                       5005\n",
      "AfD                       3619\n",
      "CSU                       2185\n",
      "Fraktionslos              1094\n",
      "Name: count, dtype: int64\n",
      "Classification report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  AfD      0.483     0.569     0.523       724\n",
      "B√ºndnis 90/Die Gr√ºnen      0.580     0.391     0.467      2437\n",
      "                  CDU      0.464     0.390     0.424      1634\n",
      "                  CSU      0.177     0.384     0.242       437\n",
      "            Die Linke      0.435     0.482     0.457      1414\n",
      "                  FDP      0.410     0.444     0.426      1001\n",
      "         Fraktionslos      0.081     0.279     0.125       219\n",
      "                  SPD      0.496     0.410     0.449      2085\n",
      "\n",
      "             accuracy                          0.423      9951\n",
      "            macro avg      0.391     0.419     0.389      9951\n",
      "         weighted avg      0.470     0.423     0.437      9951\n",
      "\n",
      "Confusion matrix:\n",
      "[[412  37  40  33  62  27  58  55]\n",
      " [116 952 205 194 330 200 163 277]\n",
      " [ 77 134 637 195 133 125 130 203]\n",
      " [ 14  45  67 168  43  24  17  59]\n",
      " [ 81 130  83  99 682 101 104 134]\n",
      " [ 43  85  88  73  73 444  76 119]\n",
      " [ 22  24  19  15  26  29  61  23]\n",
      " [ 88 234 235 174 219 134 146 855]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tfidf_no_urls.joblib']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Choose variant here (e.g., 'raw', 'no_urls', etc.)\n",
    "VARIANT = \"no_urls\"\n",
    "\n",
    "df = pd.read_csv(f\"tweets_bundestag_{VARIANT}.csv\", encoding=\"utf-8-sig\")\n",
    "min_tweet_count = 1000\n",
    "df = df[df[\"partei\"].map(df[\"partei\"].value_counts()) >= min_tweet_count]\n",
    "df = df.dropna(subset=[\"text\"])\n",
    "\n",
    "sample_size = min(50000, len(df))\n",
    "df = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "print(\"Class distribution in data:\\n\", df[\"partei\"].value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], df[\"partei\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"partei\"]\n",
    ")\n",
    "\n",
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Logistic Regression with balanced class weights\n",
    "clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0, digits=3))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save model and vectorizer for reproducibility/Streamlit\n",
    "import joblib\n",
    "joblib.dump(clf, f\"lr_model_{VARIANT}.joblib\")\n",
    "joblib.dump(vectorizer, f\"tfidf_{VARIANT}.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee95db60",
   "metadata": {},
   "source": [
    "## **7. TF-IDF + Zusatzfeatures (Emojis, Hashtags, Mentions, URLs)**\n",
    "\n",
    "Wir erweitern unser Modell um Zusatzinformationen pro Tweet:\n",
    "\n",
    "- Anzahl Emojis\n",
    "- Anzahl Hashtags\n",
    "- Anzahl Mentions\n",
    "- Anzahl URLs\n",
    "\n",
    "Die Features werden standardisiert und mit dem TF-IDF-Vektor kombiniert.  \n",
    "Danach folgt erneut ein Training mit logistischer Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a75dbc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report (with extra features):\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  AfD      0.495     0.577     0.533       724\n",
      "B√ºndnis 90/Die Gr√ºnen      0.577     0.386     0.462      2437\n",
      "                  CDU      0.462     0.382     0.419      1634\n",
      "                  CSU      0.188     0.410     0.258       437\n",
      "            Die Linke      0.431     0.480     0.454      1414\n",
      "                  FDP      0.407     0.460     0.432      1001\n",
      "         Fraktionslos      0.078     0.274     0.122       219\n",
      "                  SPD      0.501     0.410     0.451      2085\n",
      "\n",
      "             accuracy                          0.424      9951\n",
      "            macro avg      0.393     0.422     0.391      9951\n",
      "         weighted avg      0.471     0.424     0.437      9951\n",
      "\n",
      "Confusion matrix:\n",
      "[[418  30  43  37  62  36  55  43]\n",
      " [ 98 940 203 198 346 211 164 277]\n",
      " [ 75 136 625 192 137 133 128 208]\n",
      " [ 10  46  63 179  34  25  23  57]\n",
      " [ 83 134  82  91 679  99 109 137]\n",
      " [ 54  83  82  65  77 460  78 102]\n",
      " [ 19  27  19  13  24  31  60  26]\n",
      " [ 87 232 235 176 217 135 149 854]]\n",
      "Numeric feature importances (per class):\n",
      "num_emojis: 0.0000\n",
      "num_hashtags: -0.0000\n",
      "num_mentions: 0.0000\n",
      "num_urls: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "import joblib\n",
    "\n",
    "def count_emojis(text):\n",
    "    return sum(char in emoji.EMOJI_DATA for char in str(text))\n",
    "\n",
    "def count_hashtags(text):\n",
    "    return len(re.findall(r\"#\\w+\", str(text)))\n",
    "\n",
    "def count_mentions(text):\n",
    "    return len(re.findall(r\"@\\w+\", str(text)))\n",
    "\n",
    "def count_urls(text):\n",
    "    return len(re.findall(r\"http\\S+|www\\S+|https\\S+\", str(text)))\n",
    "\n",
    "# Choose best variant based on previous results\n",
    "VARIANT = \"no_urls\"\n",
    "df = pd.read_csv(f\"tweets_bundestag_{VARIANT}.csv\", encoding=\"utf-8-sig\")\n",
    "min_tweet_count = 1000\n",
    "df = df[df[\"partei\"].map(df[\"partei\"].value_counts()) >= min_tweet_count]\n",
    "df = df.dropna(subset=[\"text\"])\n",
    "\n",
    "# Add extra features\n",
    "df[\"num_emojis\"] = df[\"text\"].apply(count_emojis)\n",
    "df[\"num_hashtags\"] = df[\"text\"].apply(count_hashtags)\n",
    "df[\"num_mentions\"] = df[\"text\"].apply(count_mentions)\n",
    "df[\"num_urls\"] = df[\"text\"].apply(count_urls)\n",
    "\n",
    "sample_size = min(50000, len(df))\n",
    "df = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "X_text = df[\"text\"]\n",
    "X_extra = df[[\"num_emojis\", \"num_hashtags\", \"num_mentions\", \"num_urls\"]].values\n",
    "y = df[\"partei\"]\n",
    "\n",
    "X_train_text, X_test_text, X_train_extra, X_test_extra, y_train, y_test = train_test_split(\n",
    "    X_text, X_extra, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train_text)\n",
    "X_test_vec = vectorizer.transform(X_test_text)\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_extra_scaled = scaler.fit_transform(X_train_extra)\n",
    "X_test_extra_scaled = scaler.transform(X_test_extra)\n",
    "\n",
    "X_train_combined = hstack([X_train_vec, X_train_extra_scaled])\n",
    "X_test_combined = hstack([X_test_vec, X_test_extra_scaled])\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42)\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_combined)\n",
    "print(\"Classification report (with extra features):\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0, digits=3))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "joblib.dump(clf, f\"lr_model_extra_{VARIANT}.joblib\")\n",
    "joblib.dump(vectorizer, f\"tfidf_extra_{VARIANT}.joblib\")\n",
    "joblib.dump(scaler, f\"scaler_extra_{VARIANT}.joblib\")\n",
    "\n",
    "# Feature importances for numeric features\n",
    "coef = clf.coef_\n",
    "print(\"Numeric feature importances (per class):\")\n",
    "for i, col in enumerate([\"num_emojis\", \"num_hashtags\", \"num_mentions\", \"num_urls\"]):\n",
    "    print(f\"{col}: {coef[:, -(i+1)].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2603830",
   "metadata": {},
   "source": [
    "## **8. Feature Engineering (strukturierte Merkmale)**\n",
    "\n",
    "In diesem Schritt extrahieren wir zus√§tzliche Merkmale aus dem Text,\n",
    "die nicht durch TF-IDF oder BERT abgedeckt sind:\n",
    "\n",
    "- L√§nge des Tweets (in Zeichen/W√∂rtern)\n",
    "- durchschnittliche Wortl√§nge\n",
    "- Verh√§ltnis von Gro√übuchstaben\n",
    "- H√§ufigkeit von !, ?, ..., Emojis, Mentions, Hashtags, URLs\n",
    "- Politische Begriffe\n",
    "- Retweet-Erkennung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f602c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature file saved as tweets_bundestag_features.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "# List of important political terms (example, expand as needed)\n",
    "POLITICAL_TERMS = [\n",
    "    \"klimaschutz\", \"freiheit\", \"b√ºrgergeld\", \"migration\", \"rente\", \"gerechtigkeit\",\n",
    "    \"steuern\", \"digitalisierung\", \"gesundheit\", \"bildung\", \"europa\", \"verteidigung\",\n",
    "    \"arbeitsmarkt\", \"soziales\", \"integration\", \"umweltschutz\", \"innenpolitik\"\n",
    "]\n",
    "\n",
    "def count_political_terms(text):\n",
    "    text = str(text).lower()\n",
    "    return sum(1 for word in POLITICAL_TERMS if word in text)\n",
    "\n",
    "def uppercase_ratio(text):\n",
    "    text = str(text)\n",
    "    if len(text) == 0:\n",
    "        return 0\n",
    "    return sum(1 for c in text if c.isupper()) / len(text)\n",
    "\n",
    "def avg_word_length(text):\n",
    "    words = re.findall(r\"\\w+\", str(text))\n",
    "    if not words:\n",
    "        return 0\n",
    "    return sum(len(w) for w in words) / len(words)\n",
    "\n",
    "def multi_punct_count(text):\n",
    "    return len(re.findall(r\"[!?]{2,}\", str(text)))\n",
    "\n",
    "def count_emojis(text):\n",
    "    return sum(1 for char in str(text) if char in emoji.EMOJI_DATA)\n",
    "\n",
    "def count_hashtags(text):\n",
    "    return len(re.findall(r\"#\\w+\", str(text)))\n",
    "\n",
    "def count_mentions(text):\n",
    "    return len(re.findall(r\"@\\w+\", str(text)))\n",
    "\n",
    "def count_urls(text):\n",
    "    return len(re.findall(r\"http\\S+|www\\S+|https\\S+\", str(text)))\n",
    "\n",
    "def count_dots(text):\n",
    "    return len(re.findall(r\"\\.\\.+\", str(text)))\n",
    "\n",
    "def is_retweet(text):\n",
    "    return int(str(text).strip().lower().startswith(\"rt @\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Use the best preprocessing variant as base\n",
    "    VARIANT = \"no_urls\"\n",
    "    df = pd.read_csv(f\"tweets_bundestag_{VARIANT}.csv\", encoding=\"utf-8-sig\")\n",
    "    df = df[df[\"text\"].notna() & (df[\"text\"].str.strip() != \"\")]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Feature extraction\n",
    "    df[\"tweet_length_chars\"] = df[\"text\"].apply(len)\n",
    "    df[\"tweet_length_words\"] = df[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "    df[\"avg_word_length\"] = df[\"text\"].apply(avg_word_length)\n",
    "    df[\"uppercase_ratio\"] = df[\"text\"].apply(uppercase_ratio)\n",
    "    df[\"exclamations\"] = df[\"text\"].apply(lambda x: str(x).count(\"!\"))\n",
    "    df[\"questions\"] = df[\"text\"].apply(lambda x: str(x).count(\"?\"))\n",
    "    df[\"multi_punct_count\"] = df[\"text\"].apply(multi_punct_count)\n",
    "    df[\"political_term_count\"] = df[\"text\"].apply(count_political_terms)\n",
    "    df[\"num_emojis\"] = df[\"text\"].apply(count_emojis)\n",
    "    df[\"num_hashtags\"] = df[\"text\"].apply(count_hashtags)\n",
    "    df[\"num_mentions\"] = df[\"text\"].apply(count_mentions)\n",
    "    df[\"num_urls\"] = df[\"text\"].apply(count_urls)\n",
    "    df[\"dots\"] = df[\"text\"].apply(count_dots)\n",
    "    df[\"is_retweet\"] = df[\"text\"].apply(is_retweet)\n",
    "\n",
    "    # Save engineered features for downstream use\n",
    "    df.to_csv(\"tweets_bundestag_features.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"Feature file saved as tweets_bundestag_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f12aa2",
   "metadata": {},
   "source": [
    "## **9. Kombiniertes Modell: BERT + strukturierte Features**\n",
    "\n",
    "In diesem Schritt kombinieren wir zwei Informationsquellen:\n",
    "\n",
    "- **Textrepr√§sentation** √ºber vortrainiertes `bert-base-german-cased` (CLS-Embedding)\n",
    "- **Strukturierte Merkmale** aus dem vorherigen Feature Engineering (z.‚ÄØB. Emojis, Wortl√§nge, Gro√üschreibung, politische Begriffe etc.)\n",
    "\n",
    "Ziel ist es, die Vorhersagegenauigkeit durch die Kombination von Kontext (BERT) und Stil/Merkmalen zu verbessern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18c4148d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report (combined features):\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  AfD      0.390     0.425     0.407       200\n",
      "B√ºndnis 90/Die Gr√ºnen      0.191     0.195     0.193       200\n",
      "                  CDU      0.224     0.180     0.199       200\n",
      "                  CSU      0.357     0.410     0.381       200\n",
      "            Die Linke      0.274     0.260     0.267       200\n",
      "                  FDP      0.284     0.290     0.287       200\n",
      "         Fraktionslos      0.336     0.355     0.345       200\n",
      "                  SPD      0.192     0.175     0.183       200\n",
      "\n",
      "             accuracy                          0.286      1600\n",
      "            macro avg      0.281     0.286     0.283      1600\n",
      "         weighted avg      0.281     0.286     0.283      1600\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[85 23 13 18 10 13 23 15]\n",
      " [15 39 19 28 31 31 19 18]\n",
      " [20 28 36 31 20 21 21 23]\n",
      " [14 16 24 82 15 11 15 23]\n",
      " [25 27 16 13 52 20 19 28]\n",
      " [20 26 17 13 21 58 23 22]\n",
      " [18 23 10 18 23 19 71 18]\n",
      " [21 22 26 27 18 31 20 35]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler_combined.joblib']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. Load features extracted in 07\n",
    "df = pd.read_csv(\"tweets_bundestag_features.csv\", encoding=\"utf-8-sig\")\n",
    "min_tweet_count = 1000\n",
    "df = df[df[\"partei\"].map(df[\"partei\"].value_counts()) >= min_tweet_count]\n",
    "df = df.dropna(subset=[\"text\"])\n",
    "df = df.reset_index(drop=True)\n",
    "sample_size = min(50000, len(df))\n",
    "df = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# 2. BERT tokenizer and model (German BERT)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-german-cased\")\n",
    "model.eval()  # Eval mode\n",
    "\n",
    "def embed_texts(texts, max_len=128, batch_size=32):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            encoded = tokenizer(batch_texts, truncation=True, padding=\"max_length\", max_length=max_len, return_tensors=\"pt\")\n",
    "            output = model(**encoded)\n",
    "            # CLS token embedding (batch_size, hidden_size)\n",
    "            cls_emb = output.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            embeddings.append(cls_emb)\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "X_text = df[\"text\"].tolist()\n",
    "y = df[\"partei\"]\n",
    "\n",
    "# 3. Numeric features to use\n",
    "feature_cols = [\n",
    "    \"tweet_length_chars\", \"tweet_length_words\", \"avg_word_length\", \"uppercase_ratio\",\n",
    "    \"exclamations\", \"questions\", \"multi_punct_count\", \"political_term_count\",\n",
    "    \"num_emojis\", \"num_hashtags\", \"num_mentions\", \"num_urls\", \"dots\", \"is_retweet\"\n",
    "]\n",
    "X_numeric = df[feature_cols].values\n",
    "\n",
    "# (Optional) Balanced sampling: Max 1000 per party\n",
    "sample_per_party = 1000\n",
    "df_balanced = (\n",
    "    df.groupby(\"partei\", group_keys=False)\n",
    "      .apply(lambda x: x.sample(n=min(len(x), sample_per_party), random_state=42))\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "X_text_bal = df_balanced[\"text\"].tolist()\n",
    "X_numeric_bal = df_balanced[feature_cols].values\n",
    "y_bal = df_balanced[\"partei\"]\n",
    "\n",
    "# Train/test split on balanced data\n",
    "X_text_train, X_text_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
    "    X_text_bal, X_numeric_bal, y_bal,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_bal\n",
    ")\n",
    "\n",
    "# 4. Compute BERT embeddings (can be cached if slow)\n",
    "X_text_train_emb = embed_texts(X_text_train)\n",
    "X_text_test_emb = embed_texts(X_text_test)\n",
    "\n",
    "# 5. Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_num_train_scaled = scaler.fit_transform(X_num_train)\n",
    "X_num_test_scaled = scaler.transform(X_num_test)\n",
    "\n",
    "# 6. Combine BERT and numeric features\n",
    "X_train_combined = np.hstack([X_text_train_emb, X_num_train_scaled])\n",
    "X_test_combined = np.hstack([X_text_test_emb, X_num_test_scaled])\n",
    "\n",
    "# 7. Train Logistic Regression\n",
    "clf = LogisticRegression(max_iter=1000, class_weight='balanced', n_jobs=-1)\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_combined)\n",
    "print(\"\\nClassification report (combined features):\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0, digits=3))\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save model and scaler for reproducibility/Streamlit\n",
    "joblib.dump(clf, \"lr_model_combined.joblib\")\n",
    "joblib.dump(scaler, \"scaler_combined.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434e248",
   "metadata": {},
   "source": [
    "## 10. **Klassifikation mit TF-IDF, BERT und Feature Engineering (Random Forest)**\n",
    "\n",
    "In diesem Abschnitt kombinieren wir drei Arten von Features:\n",
    "\n",
    "- **TF-IDF-Repr√§sentationen** der Tweets  \n",
    "- **BERT-Embeddings** aus dem `bert-base-german-cased` Modell  \n",
    "- **Manuell extrahierte Features** (z.‚ÄØB. Anzahl Emojis, Gro√übuchstaben, Hashtags etc.)\n",
    "\n",
    "Das Modell zur Klassifikation ist ein **Random Forest**, der alle kombinierten Features ber√ºcksichtigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55399b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets used: 8000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load features\n",
    "df = pd.read_csv(\"tweets_bundestag_features.csv\", encoding=\"utf-8-sig\")\n",
    "min_tweet_count = 1000\n",
    "df = df[df[\"partei\"].map(df[\"partei\"].value_counts()) >= min_tweet_count]\n",
    "df = df.dropna(subset=[\"text\"])\n",
    "\n",
    "# For a quick, balanced test, sample up to 1000 tweets per party\n",
    "sample_per_party = 1000\n",
    "df_sample = (\n",
    "    df.groupby('partei', group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=min(len(x), sample_per_party), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Number of tweets used: {len(df_sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1b5e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(df_sample[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2576f8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BERT embeddings (this may take several minutes)...\n"
     ]
    }
   ],
   "source": [
    "# BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-german-cased\")\n",
    "model.eval()\n",
    "def embed_texts(texts, max_len=64):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            encoded = tokenizer(text, truncation=True, padding=\"max_length\", max_length=max_len, return_tensors=\"pt\")\n",
    "            output = model(**encoded)\n",
    "            cls_emb = output.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "            embeddings.append(cls_emb)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "print(\"Calculating BERT embeddings (this may take several minutes)...\")\n",
    "X_bert = embed_texts(df_sample[\"text\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6bcabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineered features\n",
    "feature_cols = [\n",
    "    \"tweet_length_chars\", \"tweet_length_words\", \"avg_word_length\", \"uppercase_ratio\",\n",
    "    \"exclamations\", \"questions\", \"multi_punct_count\", \"political_term_count\",\n",
    "    \"num_emojis\", \"num_hashtags\", \"num_mentions\", \"num_urls\", \"dots\", \"is_retweet\"\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "X_eng = scaler.fit_transform(df_sample[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "163b4b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  AfD      0.373     0.575     0.453       200\n",
      "B√ºndnis 90/Die Gr√ºnen      0.203     0.180     0.191       200\n",
      "                  CDU      0.191     0.175     0.183       200\n",
      "                  CSU      0.300     0.315     0.307       200\n",
      "            Die Linke      0.193     0.165     0.178       200\n",
      "                  FDP      0.342     0.255     0.292       200\n",
      "         Fraktionslos      0.295     0.395     0.338       200\n",
      "                  SPD      0.201     0.135     0.162       200\n",
      "\n",
      "             accuracy                          0.274      1600\n",
      "            macro avg      0.262     0.274     0.263      1600\n",
      "         weighted avg      0.262     0.274     0.263      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine all features\n",
    "X_all = np.hstack([X_tfidf.toarray(), X_bert, X_eng])\n",
    "y = df_sample[\"partei\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_rf = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecaca29",
   "metadata": {},
   "source": [
    "## **11. Klassifikation mit TF-IDF, BERT und Feature Engineering (Logistic Regression)**\n",
    "\n",
    "In diesem letzten Abschnitt kombinieren wir erneut:\n",
    "\n",
    "- **TF-IDF-Vektoren**\n",
    "- **BERT-Embeddings**\n",
    "- **Feature-Engineering (z.‚ÄØB. Emojis, Hashtags, Gro√üschreibung, etc.)**\n",
    "\n",
    "Diesmal kommt ein **Logistic Regression-Modell** (mit `saga`-Solver) zum Einsatz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6356be5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets used: 8000\n",
      "Calculating BERT embeddings...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load features and sample as before...\n",
    "df = pd.read_csv(\"tweets_bundestag_features.csv\", encoding=\"utf-8-sig\")\n",
    "min_tweet_count = 1000\n",
    "df = df[df[\"partei\"].map(df[\"partei\"].value_counts()) >= min_tweet_count]\n",
    "df = df.dropna(subset=[\"text\"])\n",
    "sample_per_party = 1000\n",
    "df_sample = (\n",
    "    df.groupby('partei', group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=min(len(x), sample_per_party), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(f\"Number of tweets used: {len(df_sample)}\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(df_sample[\"text\"])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-german-cased\")\n",
    "model.eval()\n",
    "def embed_texts(texts, max_len=64):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            encoded = tokenizer(text, truncation=True, padding=\"max_length\", max_length=max_len, return_tensors=\"pt\")\n",
    "            output = model(**encoded)\n",
    "            cls_emb = output.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "            embeddings.append(cls_emb)\n",
    "    return np.array(embeddings)\n",
    "print(\"Calculating BERT embeddings...\")\n",
    "X_bert = embed_texts(df_sample[\"text\"].tolist())\n",
    "\n",
    "feature_cols = [\n",
    "    \"tweet_length_chars\", \"tweet_length_words\", \"avg_word_length\", \"uppercase_ratio\",\n",
    "    \"exclamations\", \"questions\", \"multi_punct_count\", \"political_term_count\",\n",
    "    \"num_emojis\", \"num_hashtags\", \"num_mentions\", \"num_urls\", \"dots\", \"is_retweet\"\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "X_eng = scaler.fit_transform(df_sample[feature_cols])\n",
    "\n",
    "X_all = np.hstack([X_tfidf.toarray(), X_bert, X_eng])\n",
    "y = df_sample[\"partei\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20bafb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  AfD      0.459     0.510     0.483       200\n",
      "B√ºndnis 90/Die Gr√ºnen      0.256     0.260     0.258       200\n",
      "                  CDU      0.245     0.225     0.234       200\n",
      "                  CSU      0.316     0.325     0.320       200\n",
      "            Die Linke      0.271     0.245     0.257       200\n",
      "                  FDP      0.366     0.340     0.352       200\n",
      "         Fraktionslos      0.276     0.305     0.290       200\n",
      "                  SPD      0.218     0.215     0.217       200\n",
      "\n",
      "             accuracy                          0.303      1600\n",
      "            macro avg      0.301     0.303     0.302      1600\n",
      "         weighted avg      0.301     0.303     0.302      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=2000, class_weight='balanced', n_jobs=-1, solver='saga')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_logreg = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_logreg, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cb593f",
   "metadata": {},
   "source": [
    "## **12. Klassifikation mit TF-IDF, BERT und Feature Engineering (LinearSVC)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f8ba40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets used: 8000\n",
      "Calculating BERT embeddings (this may take several minutes)...\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  AfD      0.481     0.565     0.520       200\n",
      "B√ºndnis 90/Die Gr√ºnen      0.275     0.275     0.275       200\n",
      "                  CDU      0.333     0.305     0.319       200\n",
      "                  CSU      0.373     0.330     0.350       200\n",
      "            Die Linke      0.281     0.275     0.278       200\n",
      "                  FDP      0.382     0.365     0.373       200\n",
      "         Fraktionslos      0.300     0.330     0.314       200\n",
      "                  SPD      0.253     0.250     0.251       200\n",
      "\n",
      "             accuracy                          0.337      1600\n",
      "            macro avg      0.335     0.337     0.335      1600\n",
      "         weighted avg      0.335     0.337     0.335      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load features and sample as before...\n",
    "df = pd.read_csv(\"tweets_bundestag_features.csv\", encoding=\"utf-8-sig\")\n",
    "min_tweet_count = 1000\n",
    "df = df[df[\"partei\"].map(df[\"partei\"].value_counts()) >= min_tweet_count]\n",
    "df = df.dropna(subset=[\"text\"])\n",
    "sample_per_party = 1000\n",
    "df_sample = (\n",
    "    df.groupby('partei', group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=min(len(x), sample_per_party), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Number of tweets used: {len(df_sample)}\")\n",
    "\n",
    "# TF-IDF \n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(df_sample[\"text\"])\n",
    "\n",
    "# BERT \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-german-cased\")\n",
    "model.eval()\n",
    "\n",
    "def embed_texts(texts, max_len=64):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            encoded = tokenizer(text, truncation=True, padding=\"max_length\", max_length=max_len, return_tensors=\"pt\")\n",
    "            output = model(**encoded)\n",
    "            cls_emb = output.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "            embeddings.append(cls_emb)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "print(\"Calculating BERT embeddings (this may take several minutes)...\")\n",
    "X_bert = embed_texts(df_sample[\"text\"].tolist())\n",
    "\n",
    "# Engineered features\n",
    "feature_cols = [\n",
    "    \"tweet_length_chars\", \"tweet_length_words\", \"avg_word_length\", \"uppercase_ratio\",\n",
    "    \"exclamations\", \"questions\", \"multi_punct_count\", \"political_term_count\",\n",
    "    \"num_emojis\", \"num_hashtags\", \"num_mentions\", \"num_urls\", \"dots\", \"is_retweet\"\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "X_eng = scaler.fit_transform(df_sample[feature_cols])\n",
    "\n",
    "# Combine all features \n",
    "X_all = np.hstack([X_tfidf.toarray(), X_bert, X_eng])\n",
    "y = df_sample[\"partei\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and train LinearSVC\n",
    "svc_clf = LinearSVC(max_iter=10000, random_state=42)\n",
    "svc_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svc = svc_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_svc, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b8211e",
   "metadata": {},
   "source": [
    "## **13. Klassifikation mit TF-IDF, BERT und Feature Engineering (XGBoost)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1d98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets used: 8000\n",
      "Calculating BERT embeddings (this may take several minutes)...\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  AfD      0.491     0.570     0.528       200\n",
      "B√ºndnis 90/Die Gr√ºnen      0.277     0.270     0.273       200\n",
      "                  CDU      0.279     0.275     0.277       200\n",
      "                  CSU      0.379     0.385     0.382       200\n",
      "            Die Linke      0.322     0.295     0.308       200\n",
      "                  FDP      0.474     0.410     0.440       200\n",
      "         Fraktionslos      0.313     0.385     0.345       200\n",
      "                  SPD      0.228     0.195     0.210       200\n",
      "\n",
      "             accuracy                          0.348      1600\n",
      "            macro avg      0.346     0.348     0.345      1600\n",
      "         weighted avg      0.346     0.348     0.345      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load features and sample as before...\n",
    "df = pd.read_csv(\"tweets_bundestag_features.csv\", encoding=\"utf-8-sig\")\n",
    "min_tweet_count = 1000\n",
    "df = df[df[\"partei\"].map(df[\"partei\"].value_counts()) >= min_tweet_count]\n",
    "df = df.dropna(subset=[\"text\"])\n",
    "sample_per_party = 1000\n",
    "df_sample = (\n",
    "    df.groupby('partei', group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=min(len(x), sample_per_party), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Number of tweets used: {len(df_sample)}\")\n",
    "\n",
    "# Label-Encoding \n",
    "label_encoder = LabelEncoder()\n",
    "df_sample[\"label\"] = label_encoder.fit_transform(df_sample[\"partei\"])\n",
    "\n",
    "# TF-IDF \n",
    "vectorizer = TfidfVectorizer(max_features=3000)\n",
    "X_tfidf = vectorizer.fit_transform(df_sample[\"text\"])\n",
    "\n",
    "# BERT \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-german-cased\")\n",
    "model.eval()\n",
    "\n",
    "def embed_texts(texts, max_len=64):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            encoded = tokenizer(text, truncation=True, padding=\"max_length\", max_length=max_len, return_tensors=\"pt\")\n",
    "            output = model(**encoded)\n",
    "            cls_emb = output.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "            embeddings.append(cls_emb)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "print(\"Calculating BERT embeddings (this may take several minutes)...\")\n",
    "X_bert = embed_texts(df_sample[\"text\"].tolist())\n",
    "\n",
    "# Engineered features\n",
    "feature_cols = [\n",
    "    \"tweet_length_chars\", \"tweet_length_words\", \"avg_word_length\", \"uppercase_ratio\",\n",
    "    \"exclamations\", \"questions\", \"multi_punct_count\", \"political_term_count\",\n",
    "    \"num_emojis\", \"num_hashtags\", \"num_mentions\", \"num_urls\", \"dots\", \"is_retweet\"\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "X_eng = scaler.fit_transform(df_sample[feature_cols])\n",
    "\n",
    "# Combine all features \n",
    "X_all = np.hstack([X_tfidf.toarray(), X_bert, X_eng])\n",
    "y = df_sample[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Train XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(np.unique(y)),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_xgb)\n",
    "print(classification_report(y_test_labels, y_pred_labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f27dda",
   "metadata": {},
   "source": [
    "## **14. Klassifikation mit BERT Fine-Tuning**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ad9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HEHEHE\\anaconda3\\envs\\hf-fresh\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\HEHEHE\\AppData\\Local\\Temp\\ipykernel_15040\\2288613593.py:18: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min(len(x), sample_per_party), random_state=42))\n",
      "c:\\Users\\HEHEHE\\anaconda3\\envs\\hf-fresh\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets used: 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6400/6400 [00:03<00:00, 1647.37 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1600/1600 [00:00<00:00, 1742.63 examples/s]\n",
      "  0%|          | 0/2400 [00:00<?, ?it/s]c:\\Users\\HEHEHE\\anaconda3\\envs\\hf-fresh\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "  0%|          | 10/2400 [00:29<1:52:09,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0924, 'grad_norm': 8.350713729858398, 'learning_rate': 1.991666666666667e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/2400 [00:53<1:30:42,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0914, 'grad_norm': 7.881750583648682, 'learning_rate': 1.9833333333333335e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 30/2400 [01:20<1:53:48,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0913, 'grad_norm': 6.843562602996826, 'learning_rate': 1.9750000000000002e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 40/2400 [01:45<1:31:27,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0914, 'grad_norm': 8.255105972290039, 'learning_rate': 1.9666666666666666e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 50/2400 [02:10<1:38:14,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0831, 'grad_norm': 12.03885555267334, 'learning_rate': 1.9583333333333333e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñé         | 60/2400 [02:40<1:52:46,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1062, 'grad_norm': 5.906978607177734, 'learning_rate': 1.95e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 70/2400 [03:06<1:47:38,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0535, 'grad_norm': 8.258084297180176, 'learning_rate': 1.9416666666666667e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 80/2400 [03:30<1:37:15,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0316, 'grad_norm': 8.843032836914062, 'learning_rate': 1.9333333333333333e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 90/2400 [03:54<1:24:56,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9255, 'grad_norm': 8.984526634216309, 'learning_rate': 1.925e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 100/2400 [04:20<1:54:28,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9894, 'grad_norm': 8.093070030212402, 'learning_rate': 1.916666666666667e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñç         | 110/2400 [04:47<1:44:45,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9229, 'grad_norm': 9.531656265258789, 'learning_rate': 1.9083333333333338e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñå         | 120/2400 [05:14<1:38:36,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.065, 'grad_norm': 9.476533889770508, 'learning_rate': 1.9e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñå         | 130/2400 [05:42<1:45:04,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9619, 'grad_norm': 10.495087623596191, 'learning_rate': 1.8916666666666668e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 140/2400 [06:09<1:35:06,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9384, 'grad_norm': 10.851954460144043, 'learning_rate': 1.8833333333333335e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñã         | 150/2400 [06:32<1:23:11,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0271, 'grad_norm': 9.131749153137207, 'learning_rate': 1.8750000000000002e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|‚ñã         | 160/2400 [06:57<1:35:40,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.967, 'grad_norm': 8.894372940063477, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|‚ñã         | 170/2400 [07:22<1:32:29,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9586, 'grad_norm': 8.505788803100586, 'learning_rate': 1.8583333333333336e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 180/2400 [07:47<1:31:25,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9706, 'grad_norm': 10.646028518676758, 'learning_rate': 1.8500000000000002e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 190/2400 [08:12<1:31:19,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8743, 'grad_norm': 8.514060974121094, 'learning_rate': 1.8416666666666666e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 200/2400 [08:35<1:21:33,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.989, 'grad_norm': 7.239096641540527, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 210/2400 [09:01<1:30:54,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9372, 'grad_norm': 8.52074146270752, 'learning_rate': 1.825e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 220/2400 [09:26<1:31:16,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9854, 'grad_norm': 7.193432331085205, 'learning_rate': 1.8166666666666667e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñâ         | 230/2400 [09:51<1:24:33,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9008, 'grad_norm': 11.008445739746094, 'learning_rate': 1.8083333333333334e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 240/2400 [10:16<1:27:33,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9229, 'grad_norm': 7.651762962341309, 'learning_rate': 1.8e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 250/2400 [10:42<1:31:54,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8948, 'grad_norm': 8.128543853759766, 'learning_rate': 1.7916666666666667e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|‚ñà         | 260/2400 [11:07<1:27:40,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9265, 'grad_norm': 9.415719985961914, 'learning_rate': 1.7833333333333334e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|‚ñà‚ñè        | 270/2400 [11:33<1:36:18,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8687, 'grad_norm': 8.459992408752441, 'learning_rate': 1.775e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 280/2400 [11:58<1:28:29,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0015, 'grad_norm': 11.470193862915039, 'learning_rate': 1.7666666666666668e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 290/2400 [12:22<1:33:53,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9023, 'grad_norm': 13.73088264465332, 'learning_rate': 1.7583333333333335e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñé        | 300/2400 [12:48<1:30:11,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9583, 'grad_norm': 9.369878768920898, 'learning_rate': 1.7500000000000002e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|‚ñà‚ñé        | 310/2400 [13:14<1:28:32,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7307, 'grad_norm': 8.098487854003906, 'learning_rate': 1.741666666666667e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|‚ñà‚ñé        | 320/2400 [13:39<1:25:29,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7925, 'grad_norm': 10.383824348449707, 'learning_rate': 1.7333333333333336e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 330/2400 [14:03<1:25:22,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8456, 'grad_norm': 11.73619556427002, 'learning_rate': 1.7250000000000003e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 340/2400 [14:27<1:23:27,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9948, 'grad_norm': 10.942867279052734, 'learning_rate': 1.7166666666666666e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|‚ñà‚ñç        | 350/2400 [14:50<1:18:06,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7789, 'grad_norm': 10.295965194702148, 'learning_rate': 1.7083333333333333e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|‚ñà‚ñå        | 360/2400 [15:18<1:33:42,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8384, 'grad_norm': 12.921257972717285, 'learning_rate': 1.7e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|‚ñà‚ñå        | 370/2400 [15:44<1:20:51,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8516, 'grad_norm': 9.37833023071289, 'learning_rate': 1.6916666666666667e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 380/2400 [16:12<1:39:53,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9142, 'grad_norm': 9.37505054473877, 'learning_rate': 1.6833333333333334e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñã        | 390/2400 [16:38<1:16:48,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9063, 'grad_norm': 14.349824905395508, 'learning_rate': 1.675e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 400/2400 [17:02<1:22:13,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7944, 'grad_norm': 11.828536987304688, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 410/2400 [17:30<1:29:08,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8544, 'grad_norm': 9.869861602783203, 'learning_rate': 1.6583333333333334e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 420/2400 [17:57<1:30:18,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8942, 'grad_norm': 10.777247428894043, 'learning_rate': 1.65e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 430/2400 [18:23<1:24:20,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8424, 'grad_norm': 11.898816108703613, 'learning_rate': 1.6416666666666668e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 440/2400 [18:49<1:28:28,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8607, 'grad_norm': 9.69448471069336, 'learning_rate': 1.6333333333333335e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|‚ñà‚ñâ        | 450/2400 [19:14<1:15:54,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8761, 'grad_norm': 10.297186851501465, 'learning_rate': 1.6250000000000002e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|‚ñà‚ñâ        | 460/2400 [19:39<1:22:38,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0262, 'grad_norm': 9.897808074951172, 'learning_rate': 1.616666666666667e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñâ        | 470/2400 [20:10<2:01:07,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8635, 'grad_norm': 9.840559005737305, 'learning_rate': 1.6083333333333336e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 480/2400 [20:41<1:45:30,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8952, 'grad_norm': 8.786773681640625, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 490/2400 [21:08<1:18:38,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8402, 'grad_norm': 9.10578727722168, 'learning_rate': 1.5916666666666666e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|‚ñà‚ñà        | 500/2400 [21:34<1:28:35,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8793, 'grad_norm': 12.171138763427734, 'learning_rate': 1.5833333333333333e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|‚ñà‚ñà‚ñè       | 510/2400 [21:57<1:16:16,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7541, 'grad_norm': 9.735100746154785, 'learning_rate': 1.575e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 520/2400 [22:22<1:15:09,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9301, 'grad_norm': 8.795551300048828, 'learning_rate': 1.5666666666666667e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 530/2400 [22:46<1:16:11,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8512, 'grad_norm': 8.842655181884766, 'learning_rate': 1.5583333333333334e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñé       | 540/2400 [23:12<1:16:55,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9146, 'grad_norm': 11.722885131835938, 'learning_rate': 1.55e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|‚ñà‚ñà‚ñé       | 550/2400 [23:36<1:15:04,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8895, 'grad_norm': 10.276792526245117, 'learning_rate': 1.5416666666666668e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|‚ñà‚ñà‚ñé       | 560/2400 [24:00<1:11:43,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.906, 'grad_norm': 12.088305473327637, 'learning_rate': 1.5333333333333334e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 570/2400 [24:23<1:05:49,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8804, 'grad_norm': 10.379556655883789, 'learning_rate': 1.525e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 580/2400 [24:49<1:19:38,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8609, 'grad_norm': 8.468949317932129, 'learning_rate': 1.5166666666666667e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñç       | 590/2400 [25:15<1:14:37,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7178, 'grad_norm': 9.1732759475708, 'learning_rate': 1.5083333333333333e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñå       | 600/2400 [25:41<1:17:38,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8008, 'grad_norm': 20.721378326416016, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñå       | 610/2400 [26:06<1:11:04,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.772, 'grad_norm': 12.82089900970459, 'learning_rate': 1.4916666666666669e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 620/2400 [26:31<1:15:38,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8797, 'grad_norm': 12.419257164001465, 'learning_rate': 1.4833333333333336e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñã       | 630/2400 [26:56<1:11:53,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9149, 'grad_norm': 14.120026588439941, 'learning_rate': 1.4750000000000003e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 640/2400 [27:23<1:16:36,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7244, 'grad_norm': 10.985640525817871, 'learning_rate': 1.4666666666666666e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 650/2400 [27:48<1:12:02,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8367, 'grad_norm': 10.001824378967285, 'learning_rate': 1.4583333333333333e-05, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 660/2400 [28:15<1:20:12,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8795, 'grad_norm': 10.567731857299805, 'learning_rate': 1.45e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 670/2400 [28:40<1:12:08,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9033, 'grad_norm': 9.927452087402344, 'learning_rate': 1.4416666666666667e-05, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 680/2400 [29:09<1:44:24,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7699, 'grad_norm': 10.653829574584961, 'learning_rate': 1.4333333333333334e-05, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|‚ñà‚ñà‚ñâ       | 690/2400 [29:34<1:10:26,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.765, 'grad_norm': 9.977685928344727, 'learning_rate': 1.425e-05, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|‚ñà‚ñà‚ñâ       | 700/2400 [29:58<1:10:26,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8079, 'grad_norm': 10.250344276428223, 'learning_rate': 1.416666666666667e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñâ       | 710/2400 [30:23<1:06:35,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8533, 'grad_norm': 10.262310981750488, 'learning_rate': 1.4083333333333336e-05, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 720/2400 [30:47<1:06:32,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8125, 'grad_norm': 11.422394752502441, 'learning_rate': 1.4e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 730/2400 [31:11<1:08:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7338, 'grad_norm': 10.26927375793457, 'learning_rate': 1.3916666666666667e-05, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|‚ñà‚ñà‚ñà       | 740/2400 [31:34<58:30,  2.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7128, 'grad_norm': 10.187807083129883, 'learning_rate': 1.3833333333333334e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|‚ñà‚ñà‚ñà‚ñè      | 750/2400 [32:00<1:07:55,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8116, 'grad_norm': 10.47148609161377, 'learning_rate': 1.375e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 760/2400 [32:24<1:05:31,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8646, 'grad_norm': 12.134384155273438, 'learning_rate': 1.3666666666666667e-05, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 770/2400 [32:48<1:04:40,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7886, 'grad_norm': 10.6884183883667, 'learning_rate': 1.3583333333333334e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñé      | 780/2400 [33:13<1:08:04,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7649, 'grad_norm': 11.45004653930664, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 790/2400 [33:36<1:07:39,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7555, 'grad_norm': 10.690589904785156, 'learning_rate': 1.3416666666666666e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 800/2400 [34:01<1:02:58,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8264, 'grad_norm': 11.518694877624512, 'learning_rate': 1.3333333333333333e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 800/2400 [35:42<1:02:58,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7576913833618164, 'eval_runtime': 100.1813, 'eval_samples_per_second': 15.971, 'eval_steps_per_second': 1.996, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 810/2400 [36:07<1:38:23,  3.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6201, 'grad_norm': 13.11844539642334, 'learning_rate': 1.325e-05, 'epoch': 1.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 820/2400 [36:31<1:04:56,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6518, 'grad_norm': 13.063304901123047, 'learning_rate': 1.3166666666666667e-05, 'epoch': 1.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 830/2400 [36:57<1:10:53,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7198, 'grad_norm': 11.816039085388184, 'learning_rate': 1.3083333333333334e-05, 'epoch': 1.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|‚ñà‚ñà‚ñà‚ñå      | 840/2400 [37:24<1:12:13,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5583, 'grad_norm': 9.835536003112793, 'learning_rate': 1.3000000000000001e-05, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|‚ñà‚ñà‚ñà‚ñå      | 850/2400 [37:48<1:00:12,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.693, 'grad_norm': 12.552860260009766, 'learning_rate': 1.2916666666666668e-05, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 860/2400 [38:14<1:03:33,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7137, 'grad_norm': 17.303852081298828, 'learning_rate': 1.2833333333333335e-05, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñã      | 870/2400 [38:42<1:09:04,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7075, 'grad_norm': 12.022406578063965, 'learning_rate': 1.275e-05, 'epoch': 1.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 880/2400 [39:06<57:36,  2.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6343, 'grad_norm': 15.001123428344727, 'learning_rate': 1.2666666666666667e-05, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 890/2400 [39:31<1:02:39,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7173, 'grad_norm': 12.098132133483887, 'learning_rate': 1.2583333333333334e-05, 'epoch': 1.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 900/2400 [39:58<1:02:01,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6548, 'grad_norm': 13.222574234008789, 'learning_rate': 1.25e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 910/2400 [40:23<1:01:58,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3683, 'grad_norm': 10.722518920898438, 'learning_rate': 1.2416666666666667e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 920/2400 [40:48<1:00:49,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4885, 'grad_norm': 12.803043365478516, 'learning_rate': 1.2333333333333334e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 930/2400 [41:14<1:07:02,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6942, 'grad_norm': 11.307826042175293, 'learning_rate': 1.2250000000000001e-05, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 940/2400 [41:37<55:11,  2.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6242, 'grad_norm': 15.09947681427002, 'learning_rate': 1.2166666666666667e-05, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñâ      | 950/2400 [42:01<57:07,  2.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6706, 'grad_norm': 13.903898239135742, 'learning_rate': 1.2083333333333333e-05, 'epoch': 1.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 960/2400 [42:26<1:04:01,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6678, 'grad_norm': 15.672843933105469, 'learning_rate': 1.2e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 970/2400 [42:50<55:26,  2.33s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5856, 'grad_norm': 18.250471115112305, 'learning_rate': 1.1916666666666667e-05, 'epoch': 1.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 980/2400 [43:18<1:01:58,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5595, 'grad_norm': 12.843202590942383, 'learning_rate': 1.1833333333333334e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 990/2400 [43:47<1:14:06,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8077, 'grad_norm': 12.991405487060547, 'learning_rate': 1.1750000000000001e-05, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1000/2400 [44:12<57:46,  2.48s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4829, 'grad_norm': 13.41298770904541, 'learning_rate': 1.1666666666666668e-05, 'epoch': 1.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1010/2400 [44:37<56:18,  2.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5331, 'grad_norm': 11.846578598022461, 'learning_rate': 1.1583333333333335e-05, 'epoch': 1.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1020/2400 [45:02<1:00:40,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.524, 'grad_norm': 10.688423156738281, 'learning_rate': 1.15e-05, 'epoch': 1.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1030/2400 [45:25<54:28,  2.39s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5897, 'grad_norm': 14.454080581665039, 'learning_rate': 1.1416666666666667e-05, 'epoch': 1.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1040/2400 [45:50<58:07,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5323, 'grad_norm': 12.993416786193848, 'learning_rate': 1.1333333333333334e-05, 'epoch': 1.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1050/2400 [46:15<56:36,  2.52s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6085, 'grad_norm': 13.569378852844238, 'learning_rate': 1.125e-05, 'epoch': 1.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1060/2400 [46:43<1:04:39,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.533, 'grad_norm': 11.865676879882812, 'learning_rate': 1.1166666666666668e-05, 'epoch': 1.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1070/2400 [47:07<46:25,  2.09s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5333, 'grad_norm': 17.224218368530273, 'learning_rate': 1.1083333333333335e-05, 'epoch': 1.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1080/2400 [47:34<58:29,  2.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6185, 'grad_norm': 13.628844261169434, 'learning_rate': 1.1000000000000001e-05, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1090/2400 [47:57<51:25,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5349, 'grad_norm': 16.01432991027832, 'learning_rate': 1.0916666666666667e-05, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1100/2400 [48:23<58:45,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5697, 'grad_norm': 14.66815185546875, 'learning_rate': 1.0833333333333334e-05, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1110/2400 [48:49<53:45,  2.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5821, 'grad_norm': 18.68622398376465, 'learning_rate': 1.075e-05, 'epoch': 1.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1120/2400 [49:13<49:48,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4654, 'grad_norm': 16.093931198120117, 'learning_rate': 1.0666666666666667e-05, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1130/2400 [49:39<53:33,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5465, 'grad_norm': 13.624674797058105, 'learning_rate': 1.0583333333333334e-05, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1140/2400 [50:06<53:53,  2.57s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4072, 'grad_norm': 17.218704223632812, 'learning_rate': 1.0500000000000001e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1150/2400 [50:30<51:17,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4203, 'grad_norm': 13.491786003112793, 'learning_rate': 1.0416666666666668e-05, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1160/2400 [50:56<50:06,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6057, 'grad_norm': 21.41084861755371, 'learning_rate': 1.0333333333333335e-05, 'epoch': 1.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1170/2400 [51:21<50:30,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4506, 'grad_norm': 17.1430721282959, 'learning_rate': 1.025e-05, 'epoch': 1.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1180/2400 [51:46<50:48,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4426, 'grad_norm': 11.279911041259766, 'learning_rate': 1.0166666666666667e-05, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1190/2400 [52:16<53:36,  2.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5978, 'grad_norm': 16.863122940063477, 'learning_rate': 1.0083333333333334e-05, 'epoch': 1.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1200/2400 [52:40<48:02,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6821, 'grad_norm': 19.471935272216797, 'learning_rate': 1e-05, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1210/2400 [53:08<52:48,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5192, 'grad_norm': 18.33249282836914, 'learning_rate': 9.916666666666668e-06, 'epoch': 1.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1220/2400 [53:32<49:20,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5329, 'grad_norm': 17.481847763061523, 'learning_rate': 9.833333333333333e-06, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1230/2400 [53:57<49:26,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.518, 'grad_norm': 18.005775451660156, 'learning_rate': 9.75e-06, 'epoch': 1.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1240/2400 [54:23<47:38,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4665, 'grad_norm': 13.847536087036133, 'learning_rate': 9.666666666666667e-06, 'epoch': 1.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1250/2400 [54:46<41:49,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5984, 'grad_norm': 17.275070190429688, 'learning_rate': 9.583333333333335e-06, 'epoch': 1.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1260/2400 [55:12<50:07,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3546, 'grad_norm': 21.26565170288086, 'learning_rate': 9.5e-06, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1270/2400 [55:38<49:30,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4058, 'grad_norm': 13.772555351257324, 'learning_rate': 9.416666666666667e-06, 'epoch': 1.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1280/2400 [56:02<42:57,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5299, 'grad_norm': 14.189899444580078, 'learning_rate': 9.333333333333334e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1290/2400 [56:25<41:28,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3406, 'grad_norm': 16.214584350585938, 'learning_rate': 9.250000000000001e-06, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1300/2400 [56:50<45:56,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4966, 'grad_norm': 18.854604721069336, 'learning_rate': 9.166666666666666e-06, 'epoch': 1.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1310/2400 [57:15<44:44,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.291, 'grad_norm': 16.039077758789062, 'learning_rate': 9.083333333333333e-06, 'epoch': 1.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1320/2400 [57:40<43:28,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.435, 'grad_norm': 19.93840217590332, 'learning_rate': 9e-06, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1330/2400 [58:06<47:40,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4865, 'grad_norm': 22.715482711791992, 'learning_rate': 8.916666666666667e-06, 'epoch': 1.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1340/2400 [58:33<45:12,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5991, 'grad_norm': 18.223941802978516, 'learning_rate': 8.833333333333334e-06, 'epoch': 1.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1350/2400 [58:59<50:08,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5162, 'grad_norm': 15.716521263122559, 'learning_rate': 8.750000000000001e-06, 'epoch': 1.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1360/2400 [59:26<43:39,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3985, 'grad_norm': 16.687389373779297, 'learning_rate': 8.666666666666668e-06, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1370/2400 [59:50<42:46,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4647, 'grad_norm': 18.019996643066406, 'learning_rate': 8.583333333333333e-06, 'epoch': 1.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1380/2400 [1:00:13<36:52,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5152, 'grad_norm': 25.30169677734375, 'learning_rate': 8.5e-06, 'epoch': 1.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1390/2400 [1:00:42<59:45,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4299, 'grad_norm': 19.109920501708984, 'learning_rate': 8.416666666666667e-06, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1400/2400 [1:01:07<43:57,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4677, 'grad_norm': 20.164499282836914, 'learning_rate': 8.333333333333334e-06, 'epoch': 1.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1410/2400 [1:01:35<42:44,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.479, 'grad_norm': 15.223575592041016, 'learning_rate': 8.25e-06, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1420/2400 [1:02:02<45:30,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4665, 'grad_norm': 15.914782524108887, 'learning_rate': 8.166666666666668e-06, 'epoch': 1.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1430/2400 [1:02:30<46:51,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3865, 'grad_norm': 14.608563423156738, 'learning_rate': 8.083333333333334e-06, 'epoch': 1.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1440/2400 [1:02:59<47:19,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5859, 'grad_norm': 23.744998931884766, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1450/2400 [1:03:27<45:23,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5031, 'grad_norm': 17.998807907104492, 'learning_rate': 7.916666666666667e-06, 'epoch': 1.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1460/2400 [1:03:51<40:44,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3169, 'grad_norm': 18.299884796142578, 'learning_rate': 7.833333333333333e-06, 'epoch': 1.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1470/2400 [1:04:17<40:39,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4038, 'grad_norm': 22.949243545532227, 'learning_rate': 7.75e-06, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1480/2400 [1:04:42<40:52,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4138, 'grad_norm': 14.328954696655273, 'learning_rate': 7.666666666666667e-06, 'epoch': 1.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1490/2400 [1:05:09<38:48,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3707, 'grad_norm': 13.638834953308105, 'learning_rate': 7.583333333333333e-06, 'epoch': 1.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1500/2400 [1:05:34<37:29,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4681, 'grad_norm': 18.640592575073242, 'learning_rate': 7.500000000000001e-06, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1510/2400 [1:06:00<39:34,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3859, 'grad_norm': 24.20545768737793, 'learning_rate': 7.416666666666668e-06, 'epoch': 1.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1520/2400 [1:06:26<39:58,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2905, 'grad_norm': 13.466401100158691, 'learning_rate': 7.333333333333333e-06, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1530/2400 [1:06:51<33:56,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4315, 'grad_norm': 15.72610855102539, 'learning_rate': 7.25e-06, 'epoch': 1.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1540/2400 [1:07:19<35:42,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4873, 'grad_norm': 25.24359893798828, 'learning_rate': 7.166666666666667e-06, 'epoch': 1.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1550/2400 [1:07:43<31:33,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3464, 'grad_norm': 16.787086486816406, 'learning_rate': 7.083333333333335e-06, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1560/2400 [1:08:09<37:28,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4036, 'grad_norm': 17.868318557739258, 'learning_rate': 7e-06, 'epoch': 1.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1570/2400 [1:08:34<34:41,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3615, 'grad_norm': 11.634182929992676, 'learning_rate': 6.916666666666667e-06, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1580/2400 [1:09:01<36:04,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5456, 'grad_norm': 19.088659286499023, 'learning_rate': 6.833333333333334e-06, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1590/2400 [1:09:26<32:06,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3679, 'grad_norm': 19.265260696411133, 'learning_rate': 6.750000000000001e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1600/2400 [1:09:55<40:35,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5227, 'grad_norm': 22.284116744995117, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1600/2400 [1:11:35<40:35,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.688917875289917, 'eval_runtime': 99.8908, 'eval_samples_per_second': 16.017, 'eval_steps_per_second': 2.002, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1610/2400 [1:11:58<45:49,  3.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1065, 'grad_norm': 19.300519943237305, 'learning_rate': 6.5833333333333335e-06, 'epoch': 2.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1620/2400 [1:12:28<37:46,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.298, 'grad_norm': 19.776599884033203, 'learning_rate': 6.5000000000000004e-06, 'epoch': 2.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1630/2400 [1:12:55<33:05,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2363, 'grad_norm': 16.370433807373047, 'learning_rate': 6.416666666666667e-06, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1640/2400 [1:13:19<29:39,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3463, 'grad_norm': 21.05567741394043, 'learning_rate': 6.333333333333333e-06, 'epoch': 2.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1650/2400 [1:13:45<32:59,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0314, 'grad_norm': 15.867915153503418, 'learning_rate': 6.25e-06, 'epoch': 2.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1660/2400 [1:14:08<28:41,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2127, 'grad_norm': 16.802305221557617, 'learning_rate': 6.166666666666667e-06, 'epoch': 2.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1670/2400 [1:14:34<31:04,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2518, 'grad_norm': 11.283979415893555, 'learning_rate': 6.083333333333333e-06, 'epoch': 2.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1680/2400 [1:14:58<27:40,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1836, 'grad_norm': 25.37207794189453, 'learning_rate': 6e-06, 'epoch': 2.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1690/2400 [1:15:24<30:52,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1318, 'grad_norm': 18.79288673400879, 'learning_rate': 5.916666666666667e-06, 'epoch': 2.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1700/2400 [1:15:48<27:39,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2664, 'grad_norm': 21.09343147277832, 'learning_rate': 5.833333333333334e-06, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1710/2400 [1:16:12<26:40,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.145, 'grad_norm': 25.710010528564453, 'learning_rate': 5.75e-06, 'epoch': 2.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1720/2400 [1:16:38<30:09,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2212, 'grad_norm': 19.250465393066406, 'learning_rate': 5.666666666666667e-06, 'epoch': 2.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1730/2400 [1:17:03<28:04,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0865, 'grad_norm': 22.263545989990234, 'learning_rate': 5.583333333333334e-06, 'epoch': 2.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1740/2400 [1:17:27<25:01,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3375, 'grad_norm': 17.82074546813965, 'learning_rate': 5.500000000000001e-06, 'epoch': 2.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1750/2400 [1:17:52<25:11,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1203, 'grad_norm': 23.558088302612305, 'learning_rate': 5.416666666666667e-06, 'epoch': 2.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1760/2400 [1:18:17<27:07,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1688, 'grad_norm': 14.501508712768555, 'learning_rate': 5.333333333333334e-06, 'epoch': 2.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1770/2400 [1:18:42<24:54,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9079, 'grad_norm': 13.240062713623047, 'learning_rate': 5.2500000000000006e-06, 'epoch': 2.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1780/2400 [1:19:08<25:07,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2582, 'grad_norm': 19.41443634033203, 'learning_rate': 5.1666666666666675e-06, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1790/2400 [1:19:36<29:04,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0318, 'grad_norm': 15.350768089294434, 'learning_rate': 5.0833333333333335e-06, 'epoch': 2.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1800/2400 [1:20:01<23:23,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1363, 'grad_norm': 23.16328239440918, 'learning_rate': 5e-06, 'epoch': 2.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1810/2400 [1:20:29<26:14,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1654, 'grad_norm': 11.887479782104492, 'learning_rate': 4.9166666666666665e-06, 'epoch': 2.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1820/2400 [1:20:56<25:09,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.151, 'grad_norm': 17.812931060791016, 'learning_rate': 4.833333333333333e-06, 'epoch': 2.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1830/2400 [1:21:22<24:59,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1946, 'grad_norm': 18.28278350830078, 'learning_rate': 4.75e-06, 'epoch': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1840/2400 [1:21:52<24:30,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1142, 'grad_norm': 18.172550201416016, 'learning_rate': 4.666666666666667e-06, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1850/2400 [1:22:17<22:09,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2866, 'grad_norm': 17.3522891998291, 'learning_rate': 4.583333333333333e-06, 'epoch': 2.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1860/2400 [1:22:43<22:43,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9914, 'grad_norm': 21.434293746948242, 'learning_rate': 4.5e-06, 'epoch': 2.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1870/2400 [1:23:09<22:09,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1198, 'grad_norm': 12.658257484436035, 'learning_rate': 4.416666666666667e-06, 'epoch': 2.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1880/2400 [1:23:35<20:57,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1132, 'grad_norm': 19.30548667907715, 'learning_rate': 4.333333333333334e-06, 'epoch': 2.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1890/2400 [1:23:59<20:11,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.249, 'grad_norm': 19.017683029174805, 'learning_rate': 4.25e-06, 'epoch': 2.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1900/2400 [1:24:29<23:05,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2955, 'grad_norm': 24.615991592407227, 'learning_rate': 4.166666666666667e-06, 'epoch': 2.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1910/2400 [1:24:53<18:40,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1103, 'grad_norm': 23.445066452026367, 'learning_rate': 4.083333333333334e-06, 'epoch': 2.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1920/2400 [1:25:18<19:51,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1683, 'grad_norm': 16.897031784057617, 'learning_rate': 4.000000000000001e-06, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1930/2400 [1:25:42<17:04,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2083, 'grad_norm': 24.367935180664062, 'learning_rate': 3.916666666666667e-06, 'epoch': 2.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1940/2400 [1:26:08<19:58,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2411, 'grad_norm': 19.6485538482666, 'learning_rate': 3.833333333333334e-06, 'epoch': 2.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1950/2400 [1:26:33<19:38,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0714, 'grad_norm': 18.402019500732422, 'learning_rate': 3.7500000000000005e-06, 'epoch': 2.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1960/2400 [1:26:57<17:46,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.097, 'grad_norm': 18.184011459350586, 'learning_rate': 3.6666666666666666e-06, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1970/2400 [1:27:21<17:57,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0786, 'grad_norm': 17.02843475341797, 'learning_rate': 3.5833333333333335e-06, 'epoch': 2.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1980/2400 [1:27:46<17:58,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0928, 'grad_norm': 17.399471282958984, 'learning_rate': 3.5e-06, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1990/2400 [1:28:11<17:54,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2205, 'grad_norm': 24.805639266967773, 'learning_rate': 3.416666666666667e-06, 'epoch': 2.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2000/2400 [1:28:35<16:36,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1426, 'grad_norm': 19.649738311767578, 'learning_rate': 3.3333333333333333e-06, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2010/2400 [1:29:02<16:32,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.135, 'grad_norm': 19.869394302368164, 'learning_rate': 3.2500000000000002e-06, 'epoch': 2.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2020/2400 [1:29:27<16:19,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0694, 'grad_norm': 26.980609893798828, 'learning_rate': 3.1666666666666667e-06, 'epoch': 2.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2030/2400 [1:29:53<15:35,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0875, 'grad_norm': 14.382356643676758, 'learning_rate': 3.0833333333333336e-06, 'epoch': 2.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2040/2400 [1:30:20<16:12,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1235, 'grad_norm': 22.709806442260742, 'learning_rate': 3e-06, 'epoch': 2.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2050/2400 [1:30:43<13:51,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1112, 'grad_norm': 23.420310974121094, 'learning_rate': 2.916666666666667e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2060/2400 [1:31:08<13:48,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2603, 'grad_norm': 21.579143524169922, 'learning_rate': 2.8333333333333335e-06, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2070/2400 [1:31:32<12:47,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0234, 'grad_norm': 20.276546478271484, 'learning_rate': 2.7500000000000004e-06, 'epoch': 2.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2080/2400 [1:31:58<13:03,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1646, 'grad_norm': 27.041614532470703, 'learning_rate': 2.666666666666667e-06, 'epoch': 2.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2090/2400 [1:32:22<12:03,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0454, 'grad_norm': 18.662246704101562, 'learning_rate': 2.5833333333333337e-06, 'epoch': 2.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2100/2400 [1:32:45<11:31,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1797, 'grad_norm': 12.498507499694824, 'learning_rate': 2.5e-06, 'epoch': 2.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2110/2400 [1:33:11<11:45,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0962, 'grad_norm': 21.680028915405273, 'learning_rate': 2.4166666666666667e-06, 'epoch': 2.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2120/2400 [1:33:37<11:46,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0975, 'grad_norm': 16.22684669494629, 'learning_rate': 2.3333333333333336e-06, 'epoch': 2.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2130/2400 [1:34:02<11:12,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1073, 'grad_norm': 18.91463851928711, 'learning_rate': 2.25e-06, 'epoch': 2.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2140/2400 [1:34:27<11:28,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0869, 'grad_norm': 23.843061447143555, 'learning_rate': 2.166666666666667e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2150/2400 [1:34:51<09:18,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1997, 'grad_norm': 26.78914451599121, 'learning_rate': 2.0833333333333334e-06, 'epoch': 2.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2160/2400 [1:35:18<11:12,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0908, 'grad_norm': 30.965974807739258, 'learning_rate': 2.0000000000000003e-06, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2170/2400 [1:35:48<10:52,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.938, 'grad_norm': 25.372482299804688, 'learning_rate': 1.916666666666667e-06, 'epoch': 2.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2180/2400 [1:36:17<10:07,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2147, 'grad_norm': 15.326739311218262, 'learning_rate': 1.8333333333333333e-06, 'epoch': 2.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2190/2400 [1:36:46<11:52,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2166, 'grad_norm': 28.824005126953125, 'learning_rate': 1.75e-06, 'epoch': 2.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2200/2400 [1:37:11<07:54,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1776, 'grad_norm': 24.04218864440918, 'learning_rate': 1.6666666666666667e-06, 'epoch': 2.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2210/2400 [1:37:38<08:18,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9342, 'grad_norm': 25.104429244995117, 'learning_rate': 1.5833333333333333e-06, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2220/2400 [1:38:04<07:57,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3229, 'grad_norm': 29.62108039855957, 'learning_rate': 1.5e-06, 'epoch': 2.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2230/2400 [1:38:31<07:19,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1862, 'grad_norm': 24.775230407714844, 'learning_rate': 1.4166666666666667e-06, 'epoch': 2.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2240/2400 [1:38:58<07:24,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2661, 'grad_norm': 19.823972702026367, 'learning_rate': 1.3333333333333334e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2250/2400 [1:39:23<06:08,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0108, 'grad_norm': 28.994112014770508, 'learning_rate': 1.25e-06, 'epoch': 2.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2260/2400 [1:39:52<06:59,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1182, 'grad_norm': 17.156776428222656, 'learning_rate': 1.1666666666666668e-06, 'epoch': 2.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2270/2400 [1:40:18<05:24,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2698, 'grad_norm': 21.893600463867188, 'learning_rate': 1.0833333333333335e-06, 'epoch': 2.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2280/2400 [1:40:43<05:05,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0994, 'grad_norm': 17.85591697692871, 'learning_rate': 1.0000000000000002e-06, 'epoch': 2.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2290/2400 [1:41:08<04:29,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1148, 'grad_norm': 22.4663143157959, 'learning_rate': 9.166666666666666e-07, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2300/2400 [1:41:33<04:03,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.146, 'grad_norm': 24.989364624023438, 'learning_rate': 8.333333333333333e-07, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2310/2400 [1:41:57<03:55,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1007, 'grad_norm': 21.566064834594727, 'learning_rate': 7.5e-07, 'epoch': 2.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2320/2400 [1:42:21<02:59,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.07, 'grad_norm': 23.433238983154297, 'learning_rate': 6.666666666666667e-07, 'epoch': 2.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2330/2400 [1:42:48<03:26,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9919, 'grad_norm': 17.8897762298584, 'learning_rate': 5.833333333333334e-07, 'epoch': 2.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2340/2400 [1:43:11<02:32,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1614, 'grad_norm': 21.93153953552246, 'learning_rate': 5.000000000000001e-07, 'epoch': 2.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2350/2400 [1:43:36<02:01,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2465, 'grad_norm': 31.028268814086914, 'learning_rate': 4.1666666666666667e-07, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2360/2400 [1:44:02<01:45,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0441, 'grad_norm': 21.75223159790039, 'learning_rate': 3.3333333333333335e-07, 'epoch': 2.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2370/2400 [1:44:26<01:17,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1546, 'grad_norm': 23.680082321166992, 'learning_rate': 2.5000000000000004e-07, 'epoch': 2.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2380/2400 [1:44:50<00:52,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0282, 'grad_norm': 18.940141677856445, 'learning_rate': 1.6666666666666668e-07, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2390/2400 [1:45:16<00:26,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2496, 'grad_norm': 23.508712768554688, 'learning_rate': 8.333333333333334e-08, 'epoch': 2.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2400/2400 [1:45:42<00:00,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0534, 'grad_norm': 26.850053787231445, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2400/2400 [1:47:22<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.730912208557129, 'eval_runtime': 100.1057, 'eval_samples_per_second': 15.983, 'eval_steps_per_second': 1.998, 'epoch': 3.0}\n",
      "{'train_runtime': 6442.9537, 'train_samples_per_second': 2.98, 'train_steps_per_second': 0.372, 'train_loss': 1.5182314932346344, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [01:38<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  AfD       0.58      0.68      0.62       200\n",
      "B√ºndnis 90/Die Gr√ºnen       0.28      0.28      0.28       200\n",
      "                  CDU       0.34      0.29      0.31       200\n",
      "                  CSU       0.47      0.52      0.49       200\n",
      "            Die Linke       0.32      0.32      0.32       200\n",
      "                  FDP       0.51      0.43      0.47       200\n",
      "         Fraktionslos       0.39      0.43      0.41       200\n",
      "                  SPD       0.31      0.28      0.29       200\n",
      "\n",
      "             accuracy                           0.40      1600\n",
      "            macro avg       0.40      0.40      0.40      1600\n",
      "         weighted avg       0.40      0.40      0.40      1600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load features and sample as before...\n",
    "df = pd.read_csv(\"tweets_bundestag_features.csv\", encoding=\"utf-8-sig\")\n",
    "min_tweet_count = 1000\n",
    "df = df[df[\"partei\"].map(df[\"partei\"].value_counts()) >= min_tweet_count]\n",
    "df = df.dropna(subset=[\"text\"])\n",
    "\n",
    "sample_per_party = 1000\n",
    "df_sample = (\n",
    "    df.groupby(\"partei\", group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=min(len(x), sample_per_party), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Number of tweets used: {len(df_sample)}\")\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df_sample[\"label\"] = label_encoder.fit_transform(df_sample[\"partei\"])\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "# Train/test split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df_sample[\"text\"].tolist(), df_sample[\"label\"].tolist(),\n",
    "    test_size=0.2, stratify=df_sample[\"label\"], random_state=42\n",
    ")\n",
    "\n",
    "# Tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-german-cased\", num_labels=num_labels)\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "train_ds = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels})\n",
    "test_ds = Dataset.from_dict({\"text\": test_texts, \"label\": test_labels})\n",
    "\n",
    "# Tokenization\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "test_ds = test_ds.map(tokenize_function, batched=True)\n",
    "\n",
    "# Data collator for dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=False,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Fine-tune BERT\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate\n",
    "preds = trainer.predict(test_ds)\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f23389",
   "metadata": {},
   "source": [
    "## **15. Klassifikation mit TF-IDF, BERT and Feature Engineering (Neural Network)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01957e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets used: 8000\n",
      "Calculating BERT embeddings (this may take several minutes)...\n",
      "Epoch [1/50], Average Loss: 1.9946\n",
      "Epoch [11/50], Average Loss: 1.0689\n",
      "Epoch [21/50], Average Loss: 0.5920\n",
      "Epoch [31/50], Average Loss: 0.4003\n",
      "Epoch [41/50], Average Loss: 0.3145\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  AfD      0.433     0.570     0.492       200\n",
      "B√ºndnis 90/Die Gr√ºnen      0.250     0.300     0.273       200\n",
      "                  CDU      0.288     0.325     0.305       200\n",
      "                  CSU      0.421     0.410     0.415       200\n",
      "            Die Linke      0.351     0.265     0.302       200\n",
      "                  FDP      0.367     0.360     0.364       200\n",
      "         Fraktionslos      0.328     0.295     0.311       200\n",
      "                  SPD      0.248     0.185     0.212       200\n",
      "\n",
      "             accuracy                          0.339      1600\n",
      "            macro avg      0.336     0.339     0.334      1600\n",
      "         weighted avg      0.336     0.339     0.334      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load features and sample data\n",
    "df = pd.read_csv(\"tweets_bundestag_features.csv\", encoding=\"utf-8-sig\")\n",
    "min_tweet_count = 1000\n",
    "df = df[df[\"partei\"].map(df[\"partei\"].value_counts()) >= min_tweet_count]\n",
    "df = df.dropna(subset=[\"text\"])\n",
    "\n",
    "sample_per_party = 1000\n",
    "df_sample = (\n",
    "    df.groupby('partei', group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=min(len(x), sample_per_party), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Number of tweets used: {len(df_sample)}\")\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_tfidf = vectorizer.fit_transform(df_sample[\"text\"])\n",
    "\n",
    "# BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "model_bert = AutoModel.from_pretrained(\"bert-base-german-cased\")\n",
    "model_bert.eval()\n",
    "\n",
    "def embed_texts(texts, max_len=64):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            encoded = tokenizer(text, truncation=True, padding=\"max_length\", max_length=max_len, return_tensors=\"pt\")\n",
    "            output = model_bert(**encoded)\n",
    "            cls_emb = output.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "            embeddings.append(cls_emb)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "print(\"Calculating BERT embeddings (this may take several minutes)...\")\n",
    "X_bert = embed_texts(df_sample[\"text\"].tolist())\n",
    "\n",
    "# Engineered features\n",
    "feature_cols = [\n",
    "    \"tweet_length_chars\", \"tweet_length_words\", \"avg_word_length\", \"uppercase_ratio\",\n",
    "    \"exclamations\", \"questions\", \"multi_punct_count\", \"political_term_count\",\n",
    "    \"num_emojis\", \"num_hashtags\", \"num_mentions\", \"num_urls\", \"dots\", \"is_retweet\"\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "X_eng = scaler.fit_transform(df_sample[feature_cols])\n",
    "\n",
    "# Combine all features\n",
    "X_all = np.hstack([X_tfidf.toarray(), X_bert, X_eng])\n",
    "y = df_sample[\"partei\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Label encode for neural network\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_train_tensor = torch.LongTensor(y_train_encoded)\n",
    "y_test_tensor = torch.LongTensor(y_test_encoded)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Neural Network model\n",
    "input_dim = X_all.shape[1]\n",
    "hidden_dim = 512\n",
    "dropout_rate = 0.3\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, hidden_dim),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(hidden_dim),\n",
    "    nn.Dropout(dropout_rate),\n",
    "    nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(dropout_rate),\n",
    "    nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(dropout_rate),\n",
    "    nn.Linear(hidden_dim // 4, num_classes)\n",
    ")\n",
    "\n",
    "# Training setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Training\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        batch_features = batch_features.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Prediction\n",
    "model.eval()\n",
    "y_pred_encoded = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, _ in test_loader:\n",
    "        batch_features = batch_features.to(device)\n",
    "        outputs = model(batch_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_pred_encoded.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Convert back to original labels\n",
    "y_pred_nn = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "print(classification_report(y_test, y_pred_nn, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b3e3ea",
   "metadata": {},
   "source": [
    "## **16. Klassifikation mit BERT and Feature Engineering (XGBoost) als Benchmark f√ºr traditionelle ML-Modelle zum Vergleichen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed8072f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets used: 8000\n",
      "Calculating BERT embeddings (this may take several minutes)...\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  AfD      0.386     0.485     0.430       200\n",
      "B√ºndnis 90/Die Gr√ºnen      0.218     0.220     0.219       200\n",
      "                  CDU      0.241     0.230     0.235       200\n",
      "                  CSU      0.308     0.300     0.304       200\n",
      "            Die Linke      0.198     0.180     0.188       200\n",
      "                  FDP      0.309     0.250     0.276       200\n",
      "         Fraktionslos      0.273     0.360     0.310       200\n",
      "                  SPD      0.209     0.160     0.181       200\n",
      "\n",
      "             accuracy                          0.273      1600\n",
      "            macro avg      0.268     0.273     0.268      1600\n",
      "         weighted avg      0.268     0.273     0.268      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load features and sample as before...\n",
    "df = pd.read_csv(\"tweets_bundestag_features.csv\", encoding=\"utf-8-sig\")\n",
    "min_tweet_count = 1000\n",
    "df = df[df[\"partei\"].map(df[\"partei\"].value_counts()) >= min_tweet_count]\n",
    "df = df.dropna(subset=[\"text\"])\n",
    "sample_per_party = 1000\n",
    "df_sample = (\n",
    "    df.groupby('partei', group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=min(len(x), sample_per_party), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Number of tweets used: {len(df_sample)}\")\n",
    "\n",
    "# Label-Encoding \n",
    "label_encoder = LabelEncoder()\n",
    "df_sample[\"label\"] = label_encoder.fit_transform(df_sample[\"partei\"])\n",
    "\n",
    "# BERT \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-german-cased\")\n",
    "model.eval()\n",
    "\n",
    "def embed_texts(texts, max_len=64):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            encoded = tokenizer(text, truncation=True, padding=\"max_length\", max_length=max_len, return_tensors=\"pt\")\n",
    "            output = model(**encoded)\n",
    "            cls_emb = output.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "            embeddings.append(cls_emb)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "print(\"Calculating BERT embeddings (this may take several minutes)...\")\n",
    "X_bert = embed_texts(df_sample[\"text\"].tolist())\n",
    "\n",
    "# Engineered features\n",
    "feature_cols = [\n",
    "    \"tweet_length_chars\", \"tweet_length_words\", \"avg_word_length\", \"uppercase_ratio\",\n",
    "    \"exclamations\", \"questions\", \"multi_punct_count\", \"political_term_count\",\n",
    "    \"num_emojis\", \"num_hashtags\", \"num_mentions\", \"num_urls\", \"dots\", \"is_retweet\"\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "X_eng = scaler.fit_transform(df_sample[feature_cols])\n",
    "\n",
    "# Combine all features \n",
    "X_all = np.hstack([X_bert, X_eng])\n",
    "y = df_sample[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Train XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(np.unique(y)),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_xgb)\n",
    "print(classification_report(y_test_labels, y_pred_labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb59d6c",
   "metadata": {},
   "source": [
    "## **17. Klassifikation mit BERT and Feature Engineering (XGBoost) zum Vergleichen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd25a70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets used: 8000\n",
      "Calculating BERT embeddings (this may take several minutes)...\n",
      "Epoch [1/50], Average Loss: 1.9982\n",
      "Epoch [11/50], Average Loss: 1.6059\n",
      "Epoch [21/50], Average Loss: 1.3475\n",
      "Epoch [31/50], Average Loss: 1.1547\n",
      "Epoch [41/50], Average Loss: 1.0284\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  AfD      0.458     0.490     0.473       200\n",
      "B√ºndnis 90/Die Gr√ºnen      0.189     0.205     0.197       200\n",
      "                  CDU      0.228     0.210     0.219       200\n",
      "                  CSU      0.332     0.335     0.333       200\n",
      "            Die Linke      0.227     0.220     0.223       200\n",
      "                  FDP      0.331     0.290     0.309       200\n",
      "         Fraktionslos      0.257     0.290     0.272       200\n",
      "                  SPD      0.186     0.175     0.180       200\n",
      "\n",
      "             accuracy                          0.277      1600\n",
      "            macro avg      0.276     0.277     0.276      1600\n",
      "         weighted avg      0.276     0.277     0.276      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load features and sample data\n",
    "df = pd.read_csv(\"tweets_bundestag_features.csv\", encoding=\"utf-8-sig\")\n",
    "min_tweet_count = 1000\n",
    "df = df[df[\"partei\"].map(df[\"partei\"].value_counts()) >= min_tweet_count]\n",
    "df = df.dropna(subset=[\"text\"])\n",
    "\n",
    "sample_per_party = 1000\n",
    "df_sample = (\n",
    "    df.groupby('partei', group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=min(len(x), sample_per_party), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Number of tweets used: {len(df_sample)}\")\n",
    "\n",
    "# BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "model_bert = AutoModel.from_pretrained(\"bert-base-german-cased\")\n",
    "model_bert.eval()\n",
    "\n",
    "def embed_texts(texts, max_len=64):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            encoded = tokenizer(text, truncation=True, padding=\"max_length\", max_length=max_len, return_tensors=\"pt\")\n",
    "            output = model_bert(**encoded)\n",
    "            cls_emb = output.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "            embeddings.append(cls_emb)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "print(\"Calculating BERT embeddings (this may take several minutes)...\")\n",
    "X_bert = embed_texts(df_sample[\"text\"].tolist())\n",
    "\n",
    "# Engineered features\n",
    "feature_cols = [\n",
    "    \"tweet_length_chars\", \"tweet_length_words\", \"avg_word_length\", \"uppercase_ratio\",\n",
    "    \"exclamations\", \"questions\", \"multi_punct_count\", \"political_term_count\",\n",
    "    \"num_emojis\", \"num_hashtags\", \"num_mentions\", \"num_urls\", \"dots\", \"is_retweet\"\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "X_eng = scaler.fit_transform(df_sample[feature_cols])\n",
    "\n",
    "# Combine all features\n",
    "X_all = np.hstack([X_bert, X_eng])\n",
    "y = df_sample[\"partei\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Label encode for neural network\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_train_tensor = torch.LongTensor(y_train_encoded)\n",
    "y_test_tensor = torch.LongTensor(y_test_encoded)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Neural Network model\n",
    "input_dim = X_all.shape[1]\n",
    "hidden_dim = 512\n",
    "dropout_rate = 0.3\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, hidden_dim),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(hidden_dim),\n",
    "    nn.Dropout(dropout_rate),\n",
    "    nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(dropout_rate),\n",
    "    nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(dropout_rate),\n",
    "    nn.Linear(hidden_dim // 4, num_classes)\n",
    ")\n",
    "\n",
    "# Training setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Training\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        batch_features = batch_features.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Prediction\n",
    "model.eval()\n",
    "y_pred_encoded = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, _ in test_loader:\n",
    "        batch_features = batch_features.to(device)\n",
    "        outputs = model(batch_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_pred_encoded.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Convert back to original labels\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-fresh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
